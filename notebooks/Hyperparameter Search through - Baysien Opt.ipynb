{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization, JSONLogger, Events, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = os.path.dirname(os.path.abspath(\".\"))\n",
    "sys.path.insert(0, ROOT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import copy\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import tensorflow.compat.v1 as tf_v1\n",
    "# Custom modules\n",
    "from src.Utils import parse_args, random_seed_gen\n",
    "from src.Config import POLICIES, REPLAY_BUFFERS, ALGORITHMS, BASE_CONFIG, get_configuration, get_algorithm_from_variant, get_buffer_from_variant, get_policy_from_variant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainable:\n",
    "    \n",
    "    def __init__(self, env_name, *, sess_config, render, summary_dir, display_interval, epochs, \n",
    "                 goal_trials, goal_reward, seed, policy):\n",
    "        self.render = render\n",
    "        self.epochs = epochs\n",
    "        self.sess_config = sess_config\n",
    "        self.env = gym.make(env_name)\n",
    "        self.summary_dir = summary_dir\n",
    "        self.goal_trials = goal_trials\n",
    "        self.goal_reward = goal_reward\n",
    "        self.display_interval = display_interval\n",
    "        self.model_i = 1\n",
    "        self.buffer_param = copy.deepcopy(REPLAY_BUFFERS.get(\"replay_buffer\"))\n",
    "        self.policy_param = copy.deepcopy(POLICIES.get(policy))\n",
    "        self.algorithm_param = {\"function\": ALGORITHMS[\"ddqn\"][\"function\"], \"kwargs\":{}}\n",
    "        self.algorithm_param[\"kwargs\"].update(render=self.render,\n",
    "                                              goal_trials=self.goal_trials,\n",
    "                                              goal_reward=self.goal_reward,\n",
    "                                              display_interval=self.display_interval,\n",
    "                                              **BASE_CONFIG,\n",
    "                                             )\n",
    "        self.env.seed(seed)\n",
    "        \n",
    "    def __call__(self, **kwargs):\n",
    "        kwargs[\"update_interval\"] = int(kwargs[\"update_interval\"])\n",
    "        self.algorithm_param[\"kwargs\"].update(kwargs)\n",
    "        config = {\n",
    "            \"policy_param\": self.policy_param,\n",
    "            \"buffer_param\": self.buffer_param,\n",
    "            \"algorithm_param\": self.algorithm_param\n",
    "        }\n",
    "        model_name = f\"Model {self.model_i}\"\n",
    "        # Create summary directory\n",
    "        model_summary_dir = os.path.join(self.summary_dir, model_name)\n",
    "        with tf_v1.Session(config=self.sess_config) as sess:\n",
    "            buffer = get_buffer_from_variant(config)\n",
    "            policy = get_policy_from_variant(self.env, config)\n",
    "            algo = get_algorithm_from_variant(sess, self.env, policy, buffer, model_summary_dir, config)\n",
    "            sess.run(tf_v1.global_variables_initializer())\n",
    "            print(\"\\n# Training: {}\".format(model_name))\n",
    "            # Run the algorithm for given epochs\n",
    "            algo.run(epochs=self.epochs)\n",
    "            result = np.mean(algo.epoch_rewards)*(1+algo.goals_achieved/10.0)\n",
    "            # TODO: Return algorithm goal results in the end\n",
    "        # Clear replay buffer and tensorflow graph\n",
    "        buffer.clear()\n",
    "        tf_v1.reset_default_graph()\n",
    "        self.model_i += 1\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 853\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "TF_CONFIG = tf_v1.ConfigProto(gpu_options=tf_v1.GPUOptions(per_process_gpu_memory_fraction=0.75),\n",
    "                              allow_soft_placement=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/raj/anaconda3/envs/rl_venv/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/raj/anaconda3/envs/rl_venv/lib/python3.7/site-packages/tensorflow/python/ops/losses/losses_impl.py:121: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "\n",
      "# Training: Model 1\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.0407, 0.0000, total_reward: 154.0, in 20.4456 secs\n",
      "Epoch: 200, mean_losses: 0.0199, 0.0000, total_reward: 166.0, in 45.7281 secs\n",
      "Epoch: 300, mean_losses: 0.0198, 0.0000, total_reward: 200.0, in 48.1786 secs\n",
      "Epoch: 400, mean_losses: 0.0213, 0.0000, total_reward: 171.0, in 50.3367 secs\n",
      "Epoch: 500, mean_losses: 0.0227, 0.0000, total_reward: 184.0, in 52.1610 secs\n",
      "Epoch: 600, mean_losses: 0.0238, 0.0000, total_reward: 162.0, in 57.1612 secs\n",
      "Epoch: 700, mean_losses: 0.0255, 0.0000, total_reward: 200.0, in 58.1074 secs\n",
      "Epoch: 800, mean_losses: 0.0281, 0.0000, total_reward: 200.0, in 54.5382 secs\n",
      "Epoch: 900, mean_losses: 0.0304, 0.0000, total_reward: 74.0, in 50.5045 secs\n",
      "Epoch: 1000, mean_losses: 0.0318, 0.0000, total_reward: 200.0, in 50.8678 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 692 with reward 193.26\n",
      "\n",
      "# Training: Model 2\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.0183, 0.0000, total_reward: 149.0, in 28.5994 secs\n",
      "Epoch: 200, mean_losses: 0.0144, 0.0000, total_reward: 108.0, in 44.8111 secs\n",
      "Epoch: 300, mean_losses: 0.0137, 0.0000, total_reward: 185.0, in 47.0645 secs\n",
      "Epoch: 400, mean_losses: 0.0136, 0.0000, total_reward: 23.0, in 45.4258 secs\n",
      "Epoch: 500, mean_losses: 0.0135, 0.0000, total_reward: 200.0, in 48.4553 secs\n",
      "Epoch: 600, mean_losses: 0.0135, 0.0000, total_reward: 200.0, in 43.4831 secs\n",
      "Epoch: 700, mean_losses: 0.0135, 0.0000, total_reward: 200.0, in 46.7974 secs\n",
      "Epoch: 800, mean_losses: 0.0134, 0.0000, total_reward: 200.0, in 37.3930 secs\n",
      "Epoch: 900, mean_losses: 0.0133, 0.0000, total_reward: 200.0, in 43.4050 secs\n",
      "Epoch: 1000, mean_losses: 0.0132, 0.0000, total_reward: 136.0, in 38.1222 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 267 with reward 174.71\n",
      "\n",
      "# Training: Model 3\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.0209, 0.0000, total_reward: 200.0, in 33.9571 secs\n",
      "Epoch: 200, mean_losses: 0.0174, 0.0000, total_reward: 200.0, in 36.5583 secs\n",
      "Epoch: 300, mean_losses: 0.0170, 0.0000, total_reward: 200.0, in 36.6594 secs\n",
      "Epoch: 400, mean_losses: 0.0166, 0.0000, total_reward: 200.0, in 38.1649 secs\n",
      "Epoch: 500, mean_losses: 0.0159, 0.0000, total_reward: 200.0, in 37.3811 secs\n",
      "Epoch: 600, mean_losses: 0.0154, 0.0000, total_reward: 103.0, in 36.6797 secs\n",
      "Epoch: 700, mean_losses: 0.0150, 0.0000, total_reward: 146.0, in 36.9704 secs\n",
      "Epoch: 800, mean_losses: 0.0146, 0.0000, total_reward: 131.0, in 35.9856 secs\n",
      "Epoch: 900, mean_losses: 0.0143, 0.0000, total_reward: 200.0, in 37.0187 secs\n",
      "Epoch: 1000, mean_losses: 0.0140, 0.0000, total_reward: 200.0, in 41.3021 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 139 with reward 159.35\n",
      "\n",
      "# Training: Model 4\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.0917, 0.0000, total_reward: 200.0, in 27.5854 secs\n",
      "Epoch: 200, mean_losses: 0.0910, 0.0000, total_reward: 129.0, in 44.1299 secs\n",
      "Epoch: 300, mean_losses: 0.0888, 0.0000, total_reward: 175.0, in 44.1355 secs\n",
      "Epoch: 400, mean_losses: 0.0890, 0.0000, total_reward: 194.0, in 44.1885 secs\n",
      "Epoch: 500, mean_losses: 0.0913, 0.0000, total_reward: 114.0, in 41.9020 secs\n",
      "Epoch: 600, mean_losses: 0.0928, 0.0000, total_reward: 177.0, in 38.0835 secs\n",
      "Epoch: 700, mean_losses: 0.0922, 0.0000, total_reward: 126.0, in 37.3780 secs\n",
      "Epoch: 800, mean_losses: 0.0901, 0.0000, total_reward: 173.0, in 37.4154 secs\n",
      "Epoch: 900, mean_losses: 0.0872, 0.0000, total_reward: 67.0, in 39.3736 secs\n",
      "Epoch: 1000, mean_losses: 0.0867, 0.0000, total_reward: 200.0, in 44.1224 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 186 with reward 176.03\n",
      "\n",
      "# Training: Model 5\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.0524, 0.0000, total_reward: 200.0, in 17.6300 secs\n",
      "Epoch: 200, mean_losses: 0.0240, 0.0000, total_reward: 161.0, in 41.0235 secs\n",
      "Epoch: 300, mean_losses: 0.0187, 0.0000, total_reward: 200.0, in 44.3653 secs\n",
      "Epoch: 400, mean_losses: 0.0188, 0.0000, total_reward: 138.0, in 46.5987 secs\n",
      "Epoch: 500, mean_losses: 0.0202, 0.0000, total_reward: 193.0, in 45.3291 secs\n",
      "Epoch: 600, mean_losses: 0.0219, 0.0000, total_reward: 12.0, in 40.3310 secs\n",
      "Epoch: 700, mean_losses: 0.0230, 0.0000, total_reward: 144.0, in 41.9642 secs\n",
      "Epoch: 800, mean_losses: 0.0239, 0.0000, total_reward: 54.0, in 40.5744 secs\n",
      "Epoch: 900, mean_losses: 0.0250, 0.0000, total_reward: 200.0, in 46.6204 secs\n",
      "Epoch: 1000, mean_losses: 0.0261, 0.0000, total_reward: 200.0, in 45.2750 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 355 with reward 176.48\n",
      "\n",
      "# Training: Model 6\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.0577, 0.0000, total_reward: 153.0, in 28.2954 secs\n",
      "Epoch: 200, mean_losses: 0.0399, 0.0000, total_reward: 200.0, in 39.4141 secs\n",
      "Epoch: 300, mean_losses: 0.0357, 0.0000, total_reward: 200.0, in 38.5296 secs\n",
      "Epoch: 400, mean_losses: 0.0341, 0.0000, total_reward: 96.0, in 39.2375 secs\n",
      "Epoch: 500, mean_losses: 0.0331, 0.0000, total_reward: 196.0, in 42.2514 secs\n",
      "Epoch: 600, mean_losses: 0.0330, 0.0000, total_reward: 194.0, in 42.5451 secs\n",
      "Epoch: 700, mean_losses: 0.0336, 0.0000, total_reward: 125.0, in 44.0823 secs\n",
      "Epoch: 800, mean_losses: 0.0343, 0.0000, total_reward: 123.0, in 40.3440 secs\n",
      "Epoch: 900, mean_losses: 0.0346, 0.0000, total_reward: 97.0, in 40.8169 secs\n",
      "Epoch: 1000, mean_losses: 0.0344, 0.0000, total_reward: 188.0, in 39.3769 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 690 with reward 166.27\n",
      "\n",
      "# Training: Model 7\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.0421, 0.0000, total_reward: 174.0, in 43.6820 secs\n",
      "Epoch: 200, mean_losses: 0.0337, 0.0000, total_reward: 163.0, in 49.5324 secs\n",
      "Epoch: 300, mean_losses: 0.0294, 0.0000, total_reward: 143.0, in 43.7556 secs\n",
      "Epoch: 400, mean_losses: 0.0265, 0.0000, total_reward: 159.0, in 51.9024 secs\n",
      "Epoch: 500, mean_losses: 0.0246, 0.0000, total_reward: 105.0, in 49.5840 secs\n",
      "Epoch: 600, mean_losses: 0.0241, 0.0000, total_reward: 117.0, in 52.6546 secs\n",
      "Epoch: 700, mean_losses: 0.0244, 0.0000, total_reward: 14.0, in 44.5536 secs\n",
      "Epoch: 800, mean_losses: 0.0249, 0.0000, total_reward: 200.0, in 46.1482 secs\n",
      "Epoch: 900, mean_losses: 0.0255, 0.0000, total_reward: 154.0, in 49.6275 secs\n",
      "Epoch: 1000, mean_losses: 0.0259, 0.0000, total_reward: 180.0, in 51.2752 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 123 with reward 175.32\n",
      "\n",
      "# Training: Model 8\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.0281, 0.0000, total_reward: 200.0, in 31.8824 secs\n",
      "Epoch: 200, mean_losses: 0.0316, 0.0000, total_reward: 200.0, in 47.2378 secs\n",
      "Epoch: 300, mean_losses: 0.0331, 0.0000, total_reward: 200.0, in 45.8124 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 400, mean_losses: 0.0344, 0.0000, total_reward: 200.0, in 45.9473 secs\n",
      "Epoch: 500, mean_losses: 0.0354, 0.0000, total_reward: 200.0, in 44.5361 secs\n",
      "Epoch: 600, mean_losses: 0.0365, 0.0000, total_reward: 200.0, in 44.9812 secs\n",
      "Epoch: 700, mean_losses: 0.0375, 0.0000, total_reward: 182.0, in 43.8918 secs\n",
      "Epoch: 800, mean_losses: 0.0380, 0.0000, total_reward: 200.0, in 44.3290 secs\n",
      "Epoch: 900, mean_losses: 0.0378, 0.0000, total_reward: 200.0, in 43.5160 secs\n",
      "Epoch: 1000, mean_losses: 0.0372, 0.0000, total_reward: 200.0, in 43.2698 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 144 with reward 190.27\n",
      "\n",
      "# Training: Model 9\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.1400, 0.0000, total_reward: 11.0, in 2.2657 secs\n",
      "Epoch: 200, mean_losses: 0.1195, 0.0000, total_reward: 200.0, in 3.9602 secs\n",
      "Epoch: 300, mean_losses: 0.3030, 0.0000, total_reward: 200.0, in 45.7111 secs\n",
      "Epoch: 400, mean_losses: 0.3061, 0.0000, total_reward: 146.0, in 43.2785 secs\n",
      "Epoch: 500, mean_losses: 0.2872, 0.0000, total_reward: 128.0, in 41.4050 secs\n",
      "Epoch: 600, mean_losses: 0.2603, 0.0000, total_reward: 153.0, in 40.1704 secs\n",
      "Epoch: 700, mean_losses: 0.2345, 0.0000, total_reward: 154.0, in 40.1972 secs\n",
      "Epoch: 800, mean_losses: 0.2155, 0.0000, total_reward: 200.0, in 40.6072 secs\n",
      "Epoch: 900, mean_losses: 0.2038, 0.0000, total_reward: 179.0, in 41.8306 secs\n",
      "Epoch: 1000, mean_losses: 0.1975, 0.0000, total_reward: 200.0, in 45.1787 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 297 with reward 182.68\n",
      "\n",
      "# Training: Model 10\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.0451, 0.0000, total_reward: 110.0, in 26.2086 secs\n",
      "Epoch: 200, mean_losses: 0.0311, 0.0000, total_reward: 115.0, in 36.8442 secs\n",
      "Epoch: 300, mean_losses: 0.0243, 0.0000, total_reward: 116.0, in 39.1416 secs\n",
      "Epoch: 400, mean_losses: 0.0209, 0.0000, total_reward: 195.0, in 42.7198 secs\n",
      "Epoch: 500, mean_losses: 0.0202, 0.0000, total_reward: 199.0, in 43.8855 secs\n",
      "Epoch: 600, mean_losses: 0.0209, 0.0000, total_reward: 138.0, in 45.0066 secs\n",
      "Epoch: 700, mean_losses: 0.0227, 0.0000, total_reward: 195.0, in 48.1243 secs\n",
      "Epoch: 800, mean_losses: 0.0248, 0.0000, total_reward: 171.0, in 51.3938 secs\n",
      "Epoch: 900, mean_losses: 0.0270, 0.0000, total_reward: 117.0, in 50.4616 secs\n",
      "Epoch: 1000, mean_losses: 0.0293, 0.0000, total_reward: 83.0, in 54.0960 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 953 with reward 176.52\n",
      "\n",
      "# Training: Model 11\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 1.1925, 0.0000, total_reward: 190.0, in 33.7324 secs\n",
      "Epoch: 200, mean_losses: 1.0652, 0.0000, total_reward: 146.0, in 40.7235 secs\n",
      "Epoch: 300, mean_losses: 0.9530, 0.0000, total_reward: 126.0, in 37.6802 secs\n",
      "Epoch: 400, mean_losses: 0.8297, 0.0000, total_reward: 111.0, in 37.6116 secs\n",
      "Epoch: 500, mean_losses: 0.7194, 0.0000, total_reward: 200.0, in 43.4504 secs\n",
      "Epoch: 600, mean_losses: 0.6837, 0.0000, total_reward: 171.0, in 48.0768 secs\n",
      "Epoch: 700, mean_losses: 0.7106, 0.0000, total_reward: 200.0, in 51.5105 secs\n",
      "Epoch: 800, mean_losses: 0.7352, 0.0000, total_reward: 200.0, in 49.7932 secs\n",
      "Epoch: 900, mean_losses: 0.7546, 0.0000, total_reward: 82.0, in 45.3877 secs\n",
      "Epoch: 1000, mean_losses: 0.7648, 0.0000, total_reward: 200.0, in 47.2466 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 702 with reward 195.45\n",
      "\n",
      "# Training: Model 12\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.0263, 0.0000, total_reward: 200.0, in 34.1395 secs\n",
      "Epoch: 200, mean_losses: 0.0239, 0.0000, total_reward: 193.0, in 45.3060 secs\n",
      "Epoch: 300, mean_losses: 0.0224, 0.0000, total_reward: 143.0, in 46.7904 secs\n",
      "Epoch: 400, mean_losses: 0.0219, 0.0000, total_reward: 129.0, in 48.8094 secs\n",
      "Epoch: 500, mean_losses: 0.0216, 0.0000, total_reward: 111.0, in 39.1149 secs\n",
      "Epoch: 600, mean_losses: 0.0215, 0.0000, total_reward: 200.0, in 38.0699 secs\n",
      "Epoch: 700, mean_losses: 0.0209, 0.0000, total_reward: 104.0, in 39.2468 secs\n",
      "Epoch: 800, mean_losses: 0.0200, 0.0000, total_reward: 116.0, in 42.5083 secs\n",
      "Epoch: 900, mean_losses: 0.0192, 0.0000, total_reward: 153.0, in 40.0369 secs\n",
      "Epoch: 1000, mean_losses: 0.0187, 0.0000, total_reward: 200.0, in 40.4202 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 142 with reward 178.94\n",
      "\n",
      "# Training: Model 13\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.1828, 0.0000, total_reward: 125.0, in 32.0483 secs\n",
      "Epoch: 200, mean_losses: 0.1141, 0.0000, total_reward: 172.0, in 46.2815 secs\n",
      "Epoch: 300, mean_losses: 0.0935, 0.0000, total_reward: 146.0, in 43.6488 secs\n",
      "Epoch: 400, mean_losses: 0.0836, 0.0000, total_reward: 24.0, in 44.1773 secs\n",
      "Epoch: 500, mean_losses: 0.0796, 0.0000, total_reward: 192.0, in 46.2634 secs\n",
      "Epoch: 600, mean_losses: 0.0819, 0.0000, total_reward: 138.0, in 48.8526 secs\n",
      "Epoch: 700, mean_losses: 0.0914, 0.0000, total_reward: 121.0, in 50.6087 secs\n",
      "Epoch: 800, mean_losses: 0.1011, 0.0000, total_reward: 200.0, in 47.2516 secs\n",
      "Epoch: 900, mean_losses: 0.1119, 0.0000, total_reward: 200.0, in 50.2409 secs\n",
      "Epoch: 1000, mean_losses: 0.1197, 0.0000, total_reward: 165.0, in 48.4473 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 679 with reward 177.6\n",
      "\n",
      "# Training: Model 14\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.0563, 0.0000, total_reward: 200.0, in 33.5090 secs\n",
      "Epoch: 200, mean_losses: 0.0481, 0.0000, total_reward: 188.0, in 47.8557 secs\n",
      "Epoch: 300, mean_losses: 0.0458, 0.0000, total_reward: 200.0, in 46.9774 secs\n",
      "Epoch: 400, mean_losses: 0.0443, 0.0000, total_reward: 200.0, in 46.6717 secs\n",
      "Epoch: 500, mean_losses: 0.0431, 0.0000, total_reward: 75.0, in 46.9803 secs\n",
      "Epoch: 600, mean_losses: 0.0422, 0.0000, total_reward: 161.0, in 42.8390 secs\n",
      "Epoch: 700, mean_losses: 0.0413, 0.0000, total_reward: 165.0, in 40.0375 secs\n",
      "Epoch: 800, mean_losses: 0.0404, 0.0000, total_reward: 200.0, in 44.4642 secs\n",
      "Epoch: 900, mean_losses: 0.0400, 0.0000, total_reward: 193.0, in 47.2209 secs\n",
      "Epoch: 1000, mean_losses: 0.0405, 0.0000, total_reward: 200.0, in 47.9167 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 134 with reward 183.26\n",
      "\n",
      "# Training: Model 15\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.0221, 0.0000, total_reward: 151.0, in 16.3776 secs\n",
      "Epoch: 200, mean_losses: 0.0120, 0.0000, total_reward: 135.0, in 33.5248 secs\n",
      "Epoch: 300, mean_losses: 0.0086, 0.0000, total_reward: 114.0, in 33.8686 secs\n",
      "Epoch: 400, mean_losses: 0.0072, 0.0000, total_reward: 136.0, in 36.0929 secs\n",
      "Epoch: 500, mean_losses: 0.0067, 0.0000, total_reward: 112.0, in 41.2309 secs\n",
      "Epoch: 600, mean_losses: 0.0072, 0.0000, total_reward: 30.0, in 38.1682 secs\n",
      "Epoch: 700, mean_losses: 0.0079, 0.0000, total_reward: 146.0, in 42.7945 secs\n",
      "Epoch: 800, mean_losses: 0.0092, 0.0000, total_reward: 167.0, in 43.9514 secs\n",
      "Epoch: 900, mean_losses: 0.0106, 0.0000, total_reward: 103.0, in 45.4011 secs\n",
      "Epoch: 1000, mean_losses: 0.0125, 0.0000, total_reward: 200.0, in 45.5080 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 856 with reward 176.28\n",
      "\n",
      "# Training: Model 16\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.0811, 0.0000, total_reward: 200.0, in 25.6662 secs\n",
      "Epoch: 200, mean_losses: 0.0650, 0.0000, total_reward: 122.0, in 43.0499 secs\n",
      "Epoch: 300, mean_losses: 0.0618, 0.0000, total_reward: 184.0, in 44.2275 secs\n",
      "Epoch: 400, mean_losses: 0.0611, 0.0000, total_reward: 200.0, in 44.5900 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 500, mean_losses: 0.0606, 0.0000, total_reward: 143.0, in 40.8894 secs\n",
      "Epoch: 600, mean_losses: 0.0594, 0.0000, total_reward: 143.0, in 45.4671 secs\n",
      "Epoch: 700, mean_losses: 0.0598, 0.0000, total_reward: 154.0, in 45.5927 secs\n",
      "Epoch: 800, mean_losses: 0.0611, 0.0000, total_reward: 122.0, in 39.7170 secs\n",
      "Epoch: 900, mean_losses: 0.0630, 0.0000, total_reward: 200.0, in 40.0338 secs\n",
      "Epoch: 1000, mean_losses: 0.0643, 0.0000, total_reward: 200.0, in 40.8620 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 380 with reward 174.12\n",
      "\n",
      "# Training: Model 17\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.0230, 0.0000, total_reward: 200.0, in 33.5314 secs\n",
      "Epoch: 200, mean_losses: 0.0187, 0.0000, total_reward: 123.0, in 52.0828 secs\n",
      "Epoch: 300, mean_losses: 0.0186, 0.0000, total_reward: 200.0, in 52.6625 secs\n",
      "Epoch: 400, mean_losses: 0.0196, 0.0000, total_reward: 129.0, in 49.9614 secs\n",
      "Epoch: 500, mean_losses: 0.0206, 0.0000, total_reward: 200.0, in 49.8248 secs\n",
      "Epoch: 600, mean_losses: 0.0214, 0.0000, total_reward: 200.0, in 50.5547 secs\n",
      "Epoch: 700, mean_losses: 0.0217, 0.0000, total_reward: 170.0, in 44.2478 secs\n",
      "Epoch: 800, mean_losses: 0.0217, 0.0000, total_reward: 167.0, in 45.6811 secs\n",
      "Epoch: 900, mean_losses: 0.0214, 0.0000, total_reward: 200.0, in 44.6325 secs\n",
      "Epoch: 1000, mean_losses: 0.0211, 0.0000, total_reward: 200.0, in 45.6983 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 556 with reward 184.53\n",
      "\n",
      "# Training: Model 18\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.0379, 0.0000, total_reward: 200.0, in 32.8815 secs\n",
      "Epoch: 200, mean_losses: 0.0348, 0.0000, total_reward: 175.0, in 45.5952 secs\n",
      "Epoch: 300, mean_losses: 0.0342, 0.0000, total_reward: 162.0, in 46.9835 secs\n",
      "Epoch: 400, mean_losses: 0.0344, 0.0000, total_reward: 158.0, in 46.1300 secs\n",
      "Epoch: 500, mean_losses: 0.0343, 0.0000, total_reward: 200.0, in 40.8386 secs\n",
      "Epoch: 600, mean_losses: 0.0339, 0.0000, total_reward: 200.0, in 40.1468 secs\n",
      "Epoch: 700, mean_losses: 0.0335, 0.0000, total_reward: 200.0, in 39.3785 secs\n",
      "Epoch: 800, mean_losses: 0.0331, 0.0000, total_reward: 175.0, in 42.2537 secs\n",
      "Epoch: 900, mean_losses: 0.0328, 0.0000, total_reward: 46.0, in 37.3609 secs\n",
      "Epoch: 1000, mean_losses: 0.0325, 0.0000, total_reward: 182.0, in 33.6146 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 277 with reward 186.05\n",
      "\n",
      "# Training: Model 19\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.0852, 0.0000, total_reward: 131.0, in 8.5002 secs\n",
      "Epoch: 200, mean_losses: 0.0310, 0.0000, total_reward: 130.0, in 31.3434 secs\n",
      "Epoch: 300, mean_losses: 0.0196, 0.0000, total_reward: 135.0, in 32.1504 secs\n",
      "Epoch: 400, mean_losses: 0.0151, 0.0000, total_reward: 121.0, in 32.7105 secs\n",
      "Epoch: 500, mean_losses: 0.0127, 0.0000, total_reward: 150.0, in 34.7054 secs\n",
      "Epoch: 600, mean_losses: 0.0124, 0.0000, total_reward: 135.0, in 42.1270 secs\n",
      "Epoch: 700, mean_losses: 0.0152, 0.0000, total_reward: 165.0, in 42.6744 secs\n",
      "Epoch: 800, mean_losses: 0.0208, 0.0000, total_reward: 181.0, in 41.0101 secs\n",
      "Epoch: 900, mean_losses: 0.0266, 0.0000, total_reward: 194.0, in 40.8655 secs\n",
      "Epoch: 1000, mean_losses: 0.0324, 0.0000, total_reward: 200.0, in 45.2903 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 717 with reward 175.93\n",
      "\n",
      "# Training: Model 20\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.0268, 0.0000, total_reward: 200.0, in 41.7730 secs\n",
      "Epoch: 200, mean_losses: 0.0219, 0.0000, total_reward: 196.0, in 43.7968 secs\n",
      "Epoch: 300, mean_losses: 0.0196, 0.0000, total_reward: 158.0, in 45.0429 secs\n",
      "Epoch: 400, mean_losses: 0.0186, 0.0000, total_reward: 158.0, in 46.3455 secs\n",
      "Epoch: 500, mean_losses: 0.0177, 0.0000, total_reward: 147.0, in 41.7378 secs\n",
      "Epoch: 600, mean_losses: 0.0173, 0.0000, total_reward: 200.0, in 48.7078 secs\n",
      "Epoch: 700, mean_losses: 0.0170, 0.0000, total_reward: 177.0, in 46.3710 secs\n",
      "Epoch: 800, mean_losses: 0.0168, 0.0000, total_reward: 114.0, in 45.3161 secs\n",
      "Epoch: 900, mean_losses: 0.0166, 0.0000, total_reward: 158.0, in 45.6617 secs\n",
      "Epoch: 1000, mean_losses: 0.0165, 0.0000, total_reward: 198.0, in 46.3002 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 126 with reward 176.96\n",
      "\n",
      "# Training: Model 21\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.1757, 0.0000, total_reward: 167.0, in 28.3566 secs\n",
      "Epoch: 200, mean_losses: 0.0900, 0.0000, total_reward: 144.0, in 41.0606 secs\n",
      "Epoch: 300, mean_losses: 0.0673, 0.0000, total_reward: 197.0, in 46.7979 secs\n",
      "Epoch: 400, mean_losses: 0.0686, 0.0000, total_reward: 161.0, in 45.5223 secs\n",
      "Epoch: 500, mean_losses: 0.0792, 0.0000, total_reward: 113.0, in 42.4669 secs\n",
      "Epoch: 600, mean_losses: 0.0920, 0.0000, total_reward: 139.0, in 46.9030 secs\n",
      "Epoch: 700, mean_losses: 0.1081, 0.0000, total_reward: 200.0, in 48.8286 secs\n",
      "Epoch: 800, mean_losses: 0.1299, 0.0000, total_reward: 175.0, in 47.4279 secs\n",
      "Epoch: 900, mean_losses: 0.1526, 0.0000, total_reward: 200.0, in 47.7755 secs\n",
      "Epoch: 1000, mean_losses: 0.1704, 0.0000, total_reward: 200.0, in 43.3037 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 681 with reward 181.42\n",
      "\n",
      "# Training: Model 22\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.0793, 0.0000, total_reward: 200.0, in 36.0476 secs\n",
      "Epoch: 200, mean_losses: 0.0652, 0.0000, total_reward: 146.0, in 40.2102 secs\n",
      "Epoch: 300, mean_losses: 0.0585, 0.0000, total_reward: 85.0, in 37.2891 secs\n",
      "Epoch: 400, mean_losses: 0.0528, 0.0000, total_reward: 114.0, in 40.7420 secs\n",
      "Epoch: 500, mean_losses: 0.0487, 0.0000, total_reward: 198.0, in 46.5269 secs\n",
      "Epoch: 600, mean_losses: 0.0471, 0.0000, total_reward: 200.0, in 42.5571 secs\n",
      "Epoch: 700, mean_losses: 0.0480, 0.0000, total_reward: 118.0, in 42.1758 secs\n",
      "Epoch: 800, mean_losses: 0.0480, 0.0000, total_reward: 200.0, in 39.4967 secs\n",
      "Epoch: 900, mean_losses: 0.0476, 0.0000, total_reward: 141.0, in 40.7800 secs\n",
      "Epoch: 1000, mean_losses: 0.0467, 0.0000, total_reward: 200.0, in 38.7093 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 118 with reward 180.6\n",
      "\n",
      "# Training: Model 23\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.1325, 0.0000, total_reward: 103.0, in 12.3119 secs\n",
      "Epoch: 200, mean_losses: 0.0702, 0.0000, total_reward: 113.0, in 26.8733 secs\n",
      "Epoch: 300, mean_losses: 0.0572, 0.0000, total_reward: 119.0, in 30.0197 secs\n",
      "Epoch: 400, mean_losses: 0.0568, 0.0000, total_reward: 102.0, in 33.5778 secs\n",
      "Epoch: 500, mean_losses: 0.0582, 0.0000, total_reward: 131.0, in 33.3062 secs\n",
      "Epoch: 600, mean_losses: 0.0695, 0.0000, total_reward: 149.0, in 38.6634 secs\n",
      "Epoch: 700, mean_losses: 0.0887, 0.0000, total_reward: 200.0, in 41.6298 secs\n",
      "Epoch: 800, mean_losses: 0.1170, 0.0000, total_reward: 200.0, in 46.9087 secs\n",
      "Epoch: 900, mean_losses: 0.1463, 0.0000, total_reward: 200.0, in 44.2494 secs\n",
      "Epoch: 1000, mean_losses: 0.1731, 0.0000, total_reward: 200.0, in 42.3423 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 836 with reward 186.73\n",
      "\n",
      "# Training: Model 24\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.0333, 0.0000, total_reward: 176.0, in 17.1550 secs\n",
      "Epoch: 200, mean_losses: 0.0204, 0.0000, total_reward: 118.0, in 35.9939 secs\n",
      "Epoch: 300, mean_losses: 0.0164, 0.0000, total_reward: 200.0, in 40.5963 secs\n",
      "Epoch: 400, mean_losses: 0.0164, 0.0000, total_reward: 154.0, in 46.1041 secs\n",
      "Epoch: 500, mean_losses: 0.0181, 0.0000, total_reward: 200.0, in 45.9973 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 600, mean_losses: 0.0199, 0.0000, total_reward: 49.0, in 40.9173 secs\n",
      "Epoch: 700, mean_losses: 0.0210, 0.0000, total_reward: 155.0, in 40.4764 secs\n",
      "Epoch: 800, mean_losses: 0.0214, 0.0000, total_reward: 200.0, in 44.0903 secs\n",
      "Epoch: 900, mean_losses: 0.0214, 0.0000, total_reward: 200.0, in 44.1867 secs\n",
      "Epoch: 1000, mean_losses: 0.0215, 0.0000, total_reward: 191.0, in 40.4146 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 451 with reward 186.42\n",
      "\n",
      "# Training: Model 25\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.0220, 0.0000, total_reward: 153.0, in 27.1063 secs\n",
      "Epoch: 200, mean_losses: 0.0181, 0.0000, total_reward: 200.0, in 43.3068 secs\n",
      "Epoch: 300, mean_losses: 0.0175, 0.0000, total_reward: 100.0, in 44.6102 secs\n",
      "Epoch: 400, mean_losses: 0.0174, 0.0000, total_reward: 200.0, in 42.5727 secs\n",
      "Epoch: 500, mean_losses: 0.0170, 0.0000, total_reward: 200.0, in 39.2103 secs\n",
      "Epoch: 600, mean_losses: 0.0166, 0.0000, total_reward: 200.0, in 43.0173 secs\n",
      "Epoch: 700, mean_losses: 0.0163, 0.0000, total_reward: 193.0, in 41.3440 secs\n",
      "Epoch: 800, mean_losses: 0.0163, 0.0000, total_reward: 141.0, in 40.2476 secs\n",
      "Epoch: 900, mean_losses: 0.0163, 0.0000, total_reward: 15.0, in 41.0987 secs\n",
      "Epoch: 1000, mean_losses: 0.0164, 0.0000, total_reward: 111.0, in 41.0602 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 261 with reward 177.19\n",
      "\n",
      "# Training: Model 26\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.3909, 0.0000, total_reward: 200.0, in 30.9504 secs\n",
      "Epoch: 200, mean_losses: 0.3392, 0.0000, total_reward: 200.0, in 42.8546 secs\n",
      "Epoch: 300, mean_losses: 0.3214, 0.0000, total_reward: 200.0, in 41.5054 secs\n",
      "Epoch: 400, mean_losses: 0.3102, 0.0000, total_reward: 106.0, in 41.8219 secs\n",
      "Epoch: 500, mean_losses: 0.2991, 0.0000, total_reward: 186.0, in 36.3742 secs\n",
      "Epoch: 600, mean_losses: 0.2847, 0.0000, total_reward: 106.0, in 38.3588 secs\n",
      "Epoch: 700, mean_losses: 0.2756, 0.0000, total_reward: 120.0, in 39.2125 secs\n",
      "Epoch: 800, mean_losses: 0.2655, 0.0000, total_reward: 152.0, in 37.9198 secs\n",
      "Epoch: 900, mean_losses: 0.2619, 0.0000, total_reward: 161.0, in 39.7677 secs\n",
      "Epoch: 1000, mean_losses: 0.2635, 0.0000, total_reward: 113.0, in 43.4181 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 225 with reward 175.86\n",
      "\n",
      "# Training: Model 27\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.0219, 0.0000, total_reward: 200.0, in 26.2096 secs\n",
      "Epoch: 200, mean_losses: 0.0194, 0.0000, total_reward: 166.0, in 44.9808 secs\n",
      "Epoch: 300, mean_losses: 0.0193, 0.0000, total_reward: 200.0, in 48.1874 secs\n",
      "Epoch: 400, mean_losses: 0.0197, 0.0000, total_reward: 200.0, in 43.5099 secs\n",
      "Epoch: 500, mean_losses: 0.0197, 0.0000, total_reward: 200.0, in 40.9684 secs\n",
      "Epoch: 600, mean_losses: 0.0194, 0.0000, total_reward: 200.0, in 44.0407 secs\n",
      "Epoch: 700, mean_losses: 0.0190, 0.0000, total_reward: 177.0, in 40.3161 secs\n",
      "Epoch: 800, mean_losses: 0.0187, 0.0000, total_reward: 163.0, in 40.8389 secs\n",
      "Epoch: 900, mean_losses: 0.0186, 0.0000, total_reward: 180.0, in 43.1097 secs\n",
      "Epoch: 1000, mean_losses: 0.0187, 0.0000, total_reward: 200.0, in 45.5701 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 248 with reward 185.89\n",
      "\n",
      "# Training: Model 28\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.0992, 0.0000, total_reward: 148.0, in 35.8878 secs\n",
      "Epoch: 200, mean_losses: 0.0608, 0.0000, total_reward: 97.0, in 35.3458 secs\n",
      "Epoch: 300, mean_losses: 0.0473, 0.0000, total_reward: 157.0, in 40.1912 secs\n",
      "Epoch: 400, mean_losses: 0.0426, 0.0000, total_reward: 153.0, in 45.3161 secs\n",
      "Epoch: 500, mean_losses: 0.0448, 0.0000, total_reward: 173.0, in 44.5757 secs\n",
      "Epoch: 600, mean_losses: 0.0490, 0.0000, total_reward: 200.0, in 45.5320 secs\n",
      "Epoch: 700, mean_losses: 0.0525, 0.0000, total_reward: 200.0, in 43.5316 secs\n",
      "Epoch: 800, mean_losses: 0.0542, 0.0000, total_reward: 59.0, in 44.2839 secs\n",
      "Epoch: 900, mean_losses: 0.0562, 0.0000, total_reward: 140.0, in 45.7360 secs\n",
      "Epoch: 1000, mean_losses: 0.0582, 0.0000, total_reward: 134.0, in 41.9173 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 414 with reward 165.47\n",
      "\n",
      "# Training: Model 29\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.2119, 0.0000, total_reward: 173.0, in 33.6519 secs\n",
      "Epoch: 200, mean_losses: 0.1806, 0.0000, total_reward: 196.0, in 42.7836 secs\n",
      "Epoch: 300, mean_losses: 0.1601, 0.0000, total_reward: 158.0, in 41.2350 secs\n",
      "Epoch: 400, mean_losses: 0.1481, 0.0000, total_reward: 143.0, in 43.8711 secs\n",
      "Epoch: 500, mean_losses: 0.1409, 0.0000, total_reward: 200.0, in 42.0389 secs\n",
      "Epoch: 600, mean_losses: 0.1382, 0.0000, total_reward: 164.0, in 38.4307 secs\n",
      "Epoch: 700, mean_losses: 0.1359, 0.0000, total_reward: 180.0, in 39.0726 secs\n",
      "Epoch: 800, mean_losses: 0.1337, 0.0000, total_reward: 100.0, in 41.7023 secs\n",
      "Epoch: 900, mean_losses: 0.1314, 0.0000, total_reward: 115.0, in 38.0337 secs\n",
      "Epoch: 1000, mean_losses: 0.1289, 0.0000, total_reward: 200.0, in 36.6163 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 133 with reward 191.17\n",
      "\n",
      "# Training: Model 30\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.7139, 0.0000, total_reward: 200.0, in 43.9295 secs\n",
      "Epoch: 200, mean_losses: 0.5768, 0.0000, total_reward: 159.0, in 52.8704 secs\n",
      "Epoch: 300, mean_losses: 0.5132, 0.0000, total_reward: 144.0, in 53.3241 secs\n",
      "Epoch: 400, mean_losses: 0.4654, 0.0000, total_reward: 200.0, in 50.7695 secs\n",
      "Epoch: 500, mean_losses: 0.4309, 0.0000, total_reward: 200.0, in 52.6555 secs\n",
      "Epoch: 600, mean_losses: 0.4117, 0.0000, total_reward: 85.0, in 53.4062 secs\n",
      "Epoch: 700, mean_losses: 0.4094, 0.0000, total_reward: 200.0, in 47.0310 secs\n",
      "Epoch: 800, mean_losses: 0.4077, 0.0000, total_reward: 137.0, in 51.8279 secs\n",
      "Epoch: 900, mean_losses: 0.4089, 0.0000, total_reward: 170.0, in 49.1146 secs\n",
      "Epoch: 1000, mean_losses: 0.4060, 0.0000, total_reward: 200.0, in 48.8084 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 233 with reward 183.93\n",
      "\n",
      "# Training: Model 31\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.0155, 0.0000, total_reward: 147.0, in 24.8442 secs\n",
      "Epoch: 200, mean_losses: 0.0098, 0.0000, total_reward: 117.0, in 41.9149 secs\n",
      "Epoch: 300, mean_losses: 0.0088, 0.0000, total_reward: 200.0, in 41.0234 secs\n",
      "Epoch: 400, mean_losses: 0.0085, 0.0000, total_reward: 42.0, in 43.5396 secs\n",
      "Epoch: 500, mean_losses: 0.0085, 0.0000, total_reward: 200.0, in 40.7299 secs\n",
      "Epoch: 600, mean_losses: 0.0086, 0.0000, total_reward: 128.0, in 40.2895 secs\n",
      "Epoch: 700, mean_losses: 0.0087, 0.0000, total_reward: 191.0, in 40.6462 secs\n",
      "Epoch: 800, mean_losses: 0.0088, 0.0000, total_reward: 162.0, in 41.4494 secs\n",
      "Epoch: 900, mean_losses: 0.0089, 0.0000, total_reward: 200.0, in 38.4707 secs\n",
      "Epoch: 1000, mean_losses: 0.0089, 0.0000, total_reward: 200.0, in 40.0637 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 192 with reward 168.9\n",
      "\n",
      "# Training: Model 32\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.0598, 0.0000, total_reward: 137.0, in 16.6698 secs\n",
      "Epoch: 200, mean_losses: 0.0302, 0.0000, total_reward: 159.0, in 37.0507 secs\n",
      "Epoch: 300, mean_losses: 0.0221, 0.0000, total_reward: 160.0, in 39.1623 secs\n",
      "Epoch: 400, mean_losses: 0.0189, 0.0000, total_reward: 200.0, in 43.8388 secs\n",
      "Epoch: 500, mean_losses: 0.0216, 0.0000, total_reward: 188.0, in 41.3469 secs\n",
      "Epoch: 600, mean_losses: 0.0271, 0.0000, total_reward: 200.0, in 42.3766 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 700, mean_losses: 0.0340, 0.0000, total_reward: 200.0, in 45.6174 secs\n",
      "Epoch: 800, mean_losses: 0.0387, 0.0000, total_reward: 200.0, in 40.1444 secs\n",
      "Epoch: 900, mean_losses: 0.0429, 0.0000, total_reward: 200.0, in 41.1532 secs\n",
      "Epoch: 1000, mean_losses: 0.0457, 0.0000, total_reward: 167.0, in 38.7179 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 698 with reward 172.69\n",
      "\n",
      "# Training: Model 33\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.0570, 0.0000, total_reward: 111.0, in 34.0823 secs\n",
      "Epoch: 200, mean_losses: 0.0572, 0.0000, total_reward: 200.0, in 46.1437 secs\n",
      "Epoch: 300, mean_losses: 0.0578, 0.0000, total_reward: 179.0, in 40.3954 secs\n",
      "Epoch: 400, mean_losses: 0.0568, 0.0000, total_reward: 170.0, in 41.4285 secs\n",
      "Epoch: 500, mean_losses: 0.0539, 0.0000, total_reward: 200.0, in 42.5771 secs\n",
      "Epoch: 600, mean_losses: 0.0516, 0.0000, total_reward: 110.0, in 40.7675 secs\n",
      "Epoch: 700, mean_losses: 0.0502, 0.0000, total_reward: 200.0, in 42.3091 secs\n",
      "Epoch: 800, mean_losses: 0.0500, 0.0000, total_reward: 200.0, in 45.3547 secs\n",
      "Epoch: 900, mean_losses: 0.0507, 0.0000, total_reward: 168.0, in 48.0863 secs\n",
      "Epoch: 1000, mean_losses: 0.0519, 0.0000, total_reward: 126.0, in 43.7827 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 147 with reward 192.2\n",
      "\n",
      "# Training: Model 34\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.0817, 0.0000, total_reward: 200.0, in 31.8287 secs\n",
      "Epoch: 200, mean_losses: 0.0655, 0.0000, total_reward: 177.0, in 40.3567 secs\n",
      "Epoch: 300, mean_losses: 0.0584, 0.0000, total_reward: 200.0, in 38.5898 secs\n",
      "Epoch: 400, mean_losses: 0.0541, 0.0000, total_reward: 188.0, in 40.2423 secs\n",
      "Epoch: 500, mean_losses: 0.0515, 0.0000, total_reward: 163.0, in 41.6089 secs\n",
      "Epoch: 600, mean_losses: 0.0509, 0.0000, total_reward: 200.0, in 42.9949 secs\n",
      "Epoch: 700, mean_losses: 0.0516, 0.0000, total_reward: 115.0, in 44.7898 secs\n",
      "Epoch: 800, mean_losses: 0.0528, 0.0000, total_reward: 175.0, in 42.9529 secs\n",
      "Epoch: 900, mean_losses: 0.0541, 0.0000, total_reward: 122.0, in 39.2809 secs\n",
      "Epoch: 1000, mean_losses: 0.0546, 0.0000, total_reward: 45.0, in 38.2054 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 130 with reward 176.8\n",
      "\n",
      "# Training: Model 35\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.0476, 0.0000, total_reward: 39.0, in 5.3758 secs\n",
      "Epoch: 200, mean_losses: 0.0133, 0.0000, total_reward: 128.0, in 20.3332 secs\n",
      "Epoch: 300, mean_losses: 0.0089, 0.0000, total_reward: 136.0, in 34.4435 secs\n",
      "Epoch: 400, mean_losses: 0.0071, 0.0000, total_reward: 133.0, in 38.1108 secs\n",
      "Epoch: 500, mean_losses: 0.0063, 0.0000, total_reward: 136.0, in 41.8529 secs\n",
      "Epoch: 600, mean_losses: 0.0061, 0.0000, total_reward: 200.0, in 36.1404 secs\n",
      "Epoch: 700, mean_losses: 0.0064, 0.0000, total_reward: 107.0, in 40.6880 secs\n",
      "Epoch: 800, mean_losses: 0.0071, 0.0000, total_reward: 161.0, in 40.3663 secs\n",
      "Epoch: 900, mean_losses: 0.0079, 0.0000, total_reward: 200.0, in 45.6360 secs\n",
      "Epoch: 1000, mean_losses: 0.0089, 0.0000, total_reward: 165.0, in 47.3291 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 955 with reward 183.93\n",
      "\n",
      "# Training: Model 36\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 3.7765, 0.0000, total_reward: 155.0, in 23.6065 secs\n",
      "Epoch: 200, mean_losses: 5.7204, 0.0000, total_reward: 183.0, in 45.8458 secs\n",
      "Epoch: 300, mean_losses: 6.5323, 0.0000, total_reward: 200.0, in 50.9934 secs\n",
      "Epoch: 400, mean_losses: 7.6436, 0.0000, total_reward: 200.0, in 49.8557 secs\n",
      "Epoch: 500, mean_losses: 8.7456, 0.0000, total_reward: 200.0, in 51.5537 secs\n",
      "Epoch: 600, mean_losses: 10.0495, 0.0000, total_reward: 200.0, in 45.7182 secs\n",
      "Epoch: 700, mean_losses: 10.4745, 0.0000, total_reward: 200.0, in 48.9956 secs\n",
      "Epoch: 800, mean_losses: 10.5612, 0.0000, total_reward: 200.0, in 47.1815 secs\n",
      "Epoch: 900, mean_losses: 10.5577, 0.0000, total_reward: 200.0, in 51.0435 secs\n",
      "Epoch: 1000, mean_losses: 10.5751, 0.0000, total_reward: 200.0, in 50.4762 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 341 with reward 197.52\n",
      "\n",
      "# Training: Model 37\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 1.9007, 0.0000, total_reward: 88.0, in 27.5745 secs\n",
      "Epoch: 200, mean_losses: 0.9714, 0.0000, total_reward: 105.0, in 31.8375 secs\n",
      "Epoch: 300, mean_losses: 0.6728, 0.0000, total_reward: 148.0, in 38.6524 secs\n",
      "Epoch: 400, mean_losses: 0.5539, 0.0000, total_reward: 179.0, in 41.4411 secs\n",
      "Epoch: 500, mean_losses: 0.5140, 0.0000, total_reward: 161.0, in 44.5302 secs\n",
      "Epoch: 600, mean_losses: 0.5086, 0.0000, total_reward: 128.0, in 39.0175 secs\n",
      "Epoch: 700, mean_losses: 0.5153, 0.0000, total_reward: 200.0, in 44.1836 secs\n",
      "Epoch: 800, mean_losses: 0.5215, 0.0000, total_reward: 182.0, in 41.9224 secs\n",
      "Epoch: 900, mean_losses: 0.5189, 0.0000, total_reward: 188.0, in 42.0472 secs\n",
      "Epoch: 1000, mean_losses: 0.5159, 0.0000, total_reward: 200.0, in 43.6084 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 490 with reward 166.96\n",
      "\n",
      "# Training: Model 38\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.0669, 0.0000, total_reward: 154.0, in 29.1522 secs\n",
      "Epoch: 200, mean_losses: 0.0538, 0.0000, total_reward: 170.0, in 39.4984 secs\n",
      "Epoch: 300, mean_losses: 0.0485, 0.0000, total_reward: 200.0, in 42.2795 secs\n",
      "Epoch: 400, mean_losses: 0.0454, 0.0000, total_reward: 142.0, in 41.5865 secs\n",
      "Epoch: 500, mean_losses: 0.0424, 0.0000, total_reward: 146.0, in 40.9625 secs\n",
      "Epoch: 600, mean_losses: 0.0414, 0.0000, total_reward: 117.0, in 42.7275 secs\n",
      "Epoch: 700, mean_losses: 0.0414, 0.0000, total_reward: 145.0, in 39.9288 secs\n",
      "Epoch: 800, mean_losses: 0.0424, 0.0000, total_reward: 195.0, in 38.4414 secs\n",
      "Epoch: 900, mean_losses: 0.0435, 0.0000, total_reward: 178.0, in 40.4217 secs\n",
      "Epoch: 1000, mean_losses: 0.0442, 0.0000, total_reward: 112.0, in 41.1886 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 298 with reward 166.67\n",
      "\n",
      "# Training: Model 39\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.0360, 0.0000, total_reward: 155.0, in 14.9924 secs\n",
      "Epoch: 200, mean_losses: 0.0147, 0.0000, total_reward: 141.0, in 37.9529 secs\n",
      "Epoch: 300, mean_losses: 0.0095, 0.0000, total_reward: 176.0, in 42.8546 secs\n",
      "Epoch: 400, mean_losses: 0.0081, 0.0000, total_reward: 147.0, in 46.8930 secs\n",
      "Epoch: 500, mean_losses: 0.0088, 0.0000, total_reward: 166.0, in 47.5666 secs\n",
      "Epoch: 600, mean_losses: 0.0105, 0.0000, total_reward: 195.0, in 45.6632 secs\n",
      "Epoch: 700, mean_losses: 0.0119, 0.0000, total_reward: 200.0, in 43.8631 secs\n",
      "Epoch: 800, mean_losses: 0.0132, 0.0000, total_reward: 134.0, in 46.1186 secs\n",
      "Epoch: 900, mean_losses: 0.0139, 0.0000, total_reward: 97.0, in 44.8261 secs\n",
      "Epoch: 1000, mean_losses: 0.0146, 0.0000, total_reward: 20.0, in 44.4308 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 413 with reward 174.33\n",
      "\n",
      "# Training: Model 40\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.1910, 0.0000, total_reward: 136.0, in 29.2133 secs\n",
      "Epoch: 200, mean_losses: 0.1396, 0.0000, total_reward: 125.0, in 40.8544 secs\n",
      "Epoch: 300, mean_losses: 0.1204, 0.0000, total_reward: 145.0, in 40.1022 secs\n",
      "Epoch: 400, mean_losses: 0.1059, 0.0000, total_reward: 126.0, in 40.5023 secs\n",
      "Epoch: 500, mean_losses: 0.0998, 0.0000, total_reward: 200.0, in 43.9471 secs\n",
      "Epoch: 600, mean_losses: 0.0988, 0.0000, total_reward: 124.0, in 46.8360 secs\n",
      "Epoch: 700, mean_losses: 0.1018, 0.0000, total_reward: 145.0, in 45.2744 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 800, mean_losses: 0.1057, 0.0000, total_reward: 108.0, in 42.6114 secs\n",
      "Epoch: 900, mean_losses: 0.1082, 0.0000, total_reward: 200.0, in 42.7939 secs\n",
      "Epoch: 1000, mean_losses: 0.1104, 0.0000, total_reward: 150.0, in 44.0101 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 644 with reward 160.63\n",
      "\n",
      "# Training: Model 41\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.0565, 0.0000, total_reward: 200.0, in 37.8635 secs\n",
      "Epoch: 200, mean_losses: 0.0499, 0.0000, total_reward: 197.0, in 43.4141 secs\n",
      "Epoch: 300, mean_losses: 0.0471, 0.0000, total_reward: 129.0, in 42.6479 secs\n",
      "Epoch: 400, mean_losses: 0.0449, 0.0000, total_reward: 146.0, in 43.3179 secs\n",
      "Epoch: 500, mean_losses: 0.0417, 0.0000, total_reward: 115.0, in 42.4279 secs\n",
      "Epoch: 600, mean_losses: 0.0387, 0.0000, total_reward: 142.0, in 41.3528 secs\n",
      "Epoch: 700, mean_losses: 0.0365, 0.0000, total_reward: 169.0, in 41.9365 secs\n",
      "Epoch: 800, mean_losses: 0.0353, 0.0000, total_reward: 128.0, in 43.5072 secs\n",
      "Epoch: 900, mean_losses: 0.0350, 0.0000, total_reward: 101.0, in 45.2024 secs\n",
      "Epoch: 1000, mean_losses: 0.0347, 0.0000, total_reward: 105.0, in 42.8731 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 125 with reward 191.06\n",
      "\n",
      "# Training: Model 42\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.0472, 0.0000, total_reward: 200.0, in 31.8174 secs\n",
      "Epoch: 200, mean_losses: 0.0418, 0.0000, total_reward: 200.0, in 42.5211 secs\n",
      "Epoch: 300, mean_losses: 0.0394, 0.0000, total_reward: 158.0, in 44.0803 secs\n",
      "Epoch: 400, mean_losses: 0.0379, 0.0000, total_reward: 98.0, in 43.5614 secs\n",
      "Epoch: 500, mean_losses: 0.0365, 0.0000, total_reward: 172.0, in 41.6649 secs\n",
      "Epoch: 600, mean_losses: 0.0349, 0.0000, total_reward: 200.0, in 45.0064 secs\n",
      "Epoch: 700, mean_losses: 0.0339, 0.0000, total_reward: 199.0, in 44.5841 secs\n",
      "Epoch: 800, mean_losses: 0.0333, 0.0000, total_reward: 189.0, in 43.0718 secs\n",
      "Epoch: 900, mean_losses: 0.0328, 0.0000, total_reward: 200.0, in 39.1456 secs\n",
      "Epoch: 1000, mean_losses: 0.0322, 0.0000, total_reward: 200.0, in 41.3779 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 133 with reward 178.09\n",
      "\n",
      "# Training: Model 43\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.0316, 0.0000, total_reward: 163.0, in 30.6808 secs\n",
      "Epoch: 200, mean_losses: 0.0269, 0.0000, total_reward: 115.0, in 37.2081 secs\n",
      "Epoch: 300, mean_losses: 0.0241, 0.0000, total_reward: 117.0, in 34.0574 secs\n",
      "Epoch: 400, mean_losses: 0.0223, 0.0000, total_reward: 192.0, in 36.5061 secs\n",
      "Epoch: 500, mean_losses: 0.0211, 0.0000, total_reward: 118.0, in 39.2878 secs\n",
      "Epoch: 600, mean_losses: 0.0209, 0.0000, total_reward: 174.0, in 41.9755 secs\n",
      "Epoch: 700, mean_losses: 0.0218, 0.0000, total_reward: 200.0, in 47.2874 secs\n",
      "Epoch: 800, mean_losses: 0.0231, 0.0000, total_reward: 200.0, in 45.3602 secs\n",
      "Epoch: 900, mean_losses: 0.0242, 0.0000, total_reward: 159.0, in 43.2376 secs\n",
      "Epoch: 1000, mean_losses: 0.0247, 0.0000, total_reward: 200.0, in 42.4667 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 734 with reward 184.29\n",
      "\n",
      "# Training: Model 44\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.0198, 0.0000, total_reward: 200.0, in 12.9075 secs\n",
      "Epoch: 200, mean_losses: 0.0140, 0.0000, total_reward: 200.0, in 37.5045 secs\n",
      "Epoch: 300, mean_losses: 0.0129, 0.0000, total_reward: 200.0, in 40.7556 secs\n",
      "Epoch: 400, mean_losses: 0.0124, 0.0000, total_reward: 200.0, in 40.9634 secs\n",
      "Epoch: 500, mean_losses: 0.0123, 0.0000, total_reward: 200.0, in 42.1820 secs\n",
      "Epoch: 600, mean_losses: 0.0123, 0.0000, total_reward: 200.0, in 35.5591 secs\n",
      "Epoch: 700, mean_losses: 0.0124, 0.0000, total_reward: 53.0, in 36.6113 secs\n",
      "Epoch: 800, mean_losses: 0.0124, 0.0000, total_reward: 55.0, in 33.0104 secs\n",
      "Epoch: 900, mean_losses: 0.0123, 0.0000, total_reward: 200.0, in 37.4748 secs\n",
      "Epoch: 1000, mean_losses: 0.0122, 0.0000, total_reward: 200.0, in 35.9938 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 175 with reward 163.85\n",
      "\n",
      "# Training: Model 45\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.1897, 0.0000, total_reward: 126.0, in 32.7477 secs\n",
      "Epoch: 200, mean_losses: 0.1105, 0.0000, total_reward: 148.0, in 42.2408 secs\n",
      "Epoch: 300, mean_losses: 0.0872, 0.0000, total_reward: 134.0, in 47.7795 secs\n",
      "Epoch: 400, mean_losses: 0.0801, 0.0000, total_reward: 200.0, in 46.5607 secs\n",
      "Epoch: 500, mean_losses: 0.0796, 0.0000, total_reward: 150.0, in 48.0031 secs\n",
      "Epoch: 600, mean_losses: 0.0837, 0.0000, total_reward: 140.0, in 46.5468 secs\n",
      "Epoch: 700, mean_losses: 0.0864, 0.0000, total_reward: 134.0, in 42.5444 secs\n",
      "Epoch: 800, mean_losses: 0.0880, 0.0000, total_reward: 189.0, in 44.0279 secs\n",
      "Epoch: 900, mean_losses: 0.0883, 0.0000, total_reward: 114.0, in 43.1027 secs\n",
      "Epoch: 1000, mean_losses: 0.0877, 0.0000, total_reward: 200.0, in 46.1566 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 510 with reward 167.74\n",
      "\n",
      "# Training: Model 46\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.0520, 0.0000, total_reward: 16.0, in 3.3689 secs\n",
      "Epoch: 200, mean_losses: 0.0105, 0.0000, total_reward: 200.0, in 32.1961 secs\n",
      "Epoch: 300, mean_losses: 0.0075, 0.0000, total_reward: 200.0, in 52.0039 secs\n",
      "Epoch: 400, mean_losses: 0.0068, 0.0000, total_reward: 200.0, in 53.8473 secs\n",
      "Epoch: 500, mean_losses: 0.0066, 0.0000, total_reward: 168.0, in 51.2167 secs\n",
      "Epoch: 600, mean_losses: 0.0068, 0.0000, total_reward: 168.0, in 53.1164 secs\n",
      "Epoch: 700, mean_losses: 0.0069, 0.0000, total_reward: 200.0, in 47.7605 secs\n",
      "Epoch: 800, mean_losses: 0.0070, 0.0000, total_reward: 180.0, in 46.8573 secs\n",
      "Epoch: 900, mean_losses: 0.0070, 0.0000, total_reward: 42.0, in 51.6291 secs\n",
      "Epoch: 1000, mean_losses: 0.0070, 0.0000, total_reward: 146.0, in 44.2603 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 379 with reward 168.82\n",
      "\n",
      "# Training: Model 47\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.4598, 0.0000, total_reward: 175.0, in 35.1400 secs\n",
      "Epoch: 200, mean_losses: 0.3673, 0.0000, total_reward: 200.0, in 41.5414 secs\n",
      "Epoch: 300, mean_losses: 0.3466, 0.0000, total_reward: 104.0, in 40.1907 secs\n",
      "Epoch: 400, mean_losses: 0.3330, 0.0000, total_reward: 134.0, in 37.3609 secs\n",
      "Epoch: 500, mean_losses: 0.3304, 0.0000, total_reward: 195.0, in 40.5812 secs\n",
      "Epoch: 600, mean_losses: 0.3338, 0.0000, total_reward: 134.0, in 42.2969 secs\n",
      "Epoch: 700, mean_losses: 0.3370, 0.0000, total_reward: 142.0, in 45.4704 secs\n",
      "Epoch: 800, mean_losses: 0.3375, 0.0000, total_reward: 200.0, in 45.8542 secs\n",
      "Epoch: 900, mean_losses: 0.3341, 0.0000, total_reward: 121.0, in 43.4571 secs\n",
      "Epoch: 1000, mean_losses: 0.3367, 0.0000, total_reward: 145.0, in 43.9563 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 731 with reward 177.14\n",
      "\n",
      "# Training: Model 48\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.1141, 0.0000, total_reward: 107.0, in 28.8063 secs\n",
      "Epoch: 200, mean_losses: 0.0987, 0.0000, total_reward: 150.0, in 38.1011 secs\n",
      "Epoch: 300, mean_losses: 0.0898, 0.0000, total_reward: 139.0, in 44.3112 secs\n",
      "Epoch: 400, mean_losses: 0.0846, 0.0000, total_reward: 200.0, in 42.2364 secs\n",
      "Epoch: 500, mean_losses: 0.0816, 0.0000, total_reward: 200.0, in 42.4651 secs\n",
      "Epoch: 600, mean_losses: 0.0800, 0.0000, total_reward: 200.0, in 40.9184 secs\n",
      "Epoch: 700, mean_losses: 0.0783, 0.0000, total_reward: 187.0, in 40.7408 secs\n",
      "Epoch: 800, mean_losses: 0.0766, 0.0000, total_reward: 146.0, in 40.3732 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 900, mean_losses: 0.0749, 0.0000, total_reward: 200.0, in 40.6610 secs\n",
      "Epoch: 1000, mean_losses: 0.0739, 0.0000, total_reward: 67.0, in 42.1083 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 287 with reward 176.71\n",
      "\n",
      "# Training: Model 49\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.0170, 0.0000, total_reward: 200.0, in 20.3560 secs\n",
      "Epoch: 200, mean_losses: 0.0157, 0.0000, total_reward: 157.0, in 47.5421 secs\n",
      "Epoch: 300, mean_losses: 0.0157, 0.0000, total_reward: 155.0, in 44.0347 secs\n",
      "Epoch: 400, mean_losses: 0.0153, 0.0000, total_reward: 200.0, in 38.0384 secs\n",
      "Epoch: 500, mean_losses: 0.0149, 0.0000, total_reward: 200.0, in 41.6793 secs\n",
      "Epoch: 600, mean_losses: 0.0146, 0.0000, total_reward: 200.0, in 42.9326 secs\n",
      "Epoch: 700, mean_losses: 0.0147, 0.0000, total_reward: 200.0, in 45.8003 secs\n",
      "Epoch: 800, mean_losses: 0.0149, 0.0000, total_reward: 100.0, in 40.1291 secs\n",
      "Epoch: 900, mean_losses: 0.0150, 0.0000, total_reward: 200.0, in 32.6992 secs\n",
      "Epoch: 1000, mean_losses: 0.0150, 0.0000, total_reward: 200.0, in 43.2343 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 176 with reward 188.96\n",
      "\n",
      "# Training: Model 50\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.4707, 0.0000, total_reward: 167.0, in 36.9112 secs\n",
      "Epoch: 200, mean_losses: 0.3964, 0.0000, total_reward: 200.0, in 43.4655 secs\n",
      "Epoch: 300, mean_losses: 0.3575, 0.0000, total_reward: 160.0, in 40.3559 secs\n",
      "Epoch: 400, mean_losses: 0.3338, 0.0000, total_reward: 200.0, in 40.0478 secs\n",
      "Epoch: 500, mean_losses: 0.3084, 0.0000, total_reward: 175.0, in 43.4924 secs\n",
      "Epoch: 600, mean_losses: 0.2898, 0.0000, total_reward: 200.0, in 41.5165 secs\n",
      "Epoch: 700, mean_losses: 0.2728, 0.0000, total_reward: 182.0, in 42.2466 secs\n",
      "Epoch: 800, mean_losses: 0.2591, 0.0000, total_reward: 200.0, in 44.7657 secs\n",
      "Epoch: 900, mean_losses: 0.2506, 0.0000, total_reward: 200.0, in 45.5934 secs\n",
      "Epoch: 1000, mean_losses: 0.2487, 0.0000, total_reward: 176.0, in 46.7566 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 124 with reward 181.2\n",
      "\n",
      "# Training: Model 51\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.0354, 0.0000, total_reward: 200.0, in 37.2983 secs\n",
      "Epoch: 200, mean_losses: 0.0312, 0.0000, total_reward: 195.0, in 39.7361 secs\n",
      "Epoch: 300, mean_losses: 0.0271, 0.0000, total_reward: 200.0, in 39.5246 secs\n",
      "Epoch: 400, mean_losses: 0.0244, 0.0000, total_reward: 164.0, in 39.8058 secs\n",
      "Epoch: 500, mean_losses: 0.0224, 0.0000, total_reward: 107.0, in 37.5736 secs\n",
      "Epoch: 600, mean_losses: 0.0211, 0.0000, total_reward: 117.0, in 41.0973 secs\n",
      "Epoch: 700, mean_losses: 0.0206, 0.0000, total_reward: 156.0, in 43.9923 secs\n",
      "Epoch: 800, mean_losses: 0.0202, 0.0000, total_reward: 105.0, in 41.0737 secs\n",
      "Epoch: 900, mean_losses: 0.0200, 0.0000, total_reward: 137.0, in 42.8724 secs\n",
      "Epoch: 1000, mean_losses: 0.0200, 0.0000, total_reward: 179.0, in 40.4557 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 125 with reward 178.22\n"
     ]
    }
   ],
   "source": [
    "date_time = datetime.now().strftime(\"%d.%m.%Y %H.%M\")\n",
    "env_name = \"CartPole-v0\"\n",
    "algorithm = \"ddqn\"\n",
    "policy = \"greedy_epsilon\"\n",
    "summary_dir = os.path.join(\"/home/raj/summaries\", f\"{env_name}-{algorithm}-{policy}-{date_time}\")\n",
    "setup_kwargs = dict(\n",
    "    env_name=env_name,\n",
    "    sess_config=TF_CONFIG,\n",
    "    render=False,\n",
    "    summary_dir=summary_dir,\n",
    "    display_interval=100,\n",
    "    epochs=1000,\n",
    "    goal_trials=100,\n",
    "    goal_reward=200,\n",
    "    seed=seed,\n",
    "    policy=policy,\n",
    ")\n",
    "\n",
    "param_bounds = {\n",
    "    \"lr\": (0.8, 1),\n",
    "    \"df\": (0.8, 1),\n",
    "    \"tau\": (0.5, 1),\n",
    "    \"update_interval\": (1, 25),\n",
    "}\n",
    "\n",
    "trainable = Trainable(**setup_kwargs)\n",
    "\n",
    "optimizer = BayesianOptimization(\n",
    "            f=trainable,\n",
    "            pbounds=param_bounds,\n",
    "            random_state=seed,\n",
    ")\n",
    "\n",
    "log_file = os.path.join(summary_dir, \"logs.json\")\n",
    "logger = JSONLogger(path=log_file)\n",
    "optimizer.subscribe(Events.OPTMIZATION_STEP, logger)\n",
    "\n",
    "optimizer.probe(\n",
    "    params=[0.9, 0.9, 0.88, 4],\n",
    "    lazy=True,\n",
    ")\n",
    "\n",
    "optimizer.maximize(\n",
    "    init_points=10,\n",
    "    n_iter=40,\n",
    "    acq=\"ei\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': 178.804,\n",
       " 'params': {'df': 0.9955604903914581,\n",
       "  'lr': 0.9888760668246095,\n",
       "  'tau': 0.6709917974498818,\n",
       "  'update_interval': 23.761169610884398}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Training: Model 102\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.0093, 0.0000, total_reward: 10.0, in 3.4066 secs\n",
      "Epoch: 200, mean_losses: 0.0054, 0.0000, total_reward: 10.0, in 2.2112 secs\n",
      "Epoch: 300, mean_losses: 0.0039, 0.0000, total_reward: 9.0, in 2.7361 secs\n",
      "Epoch: 400, mean_losses: 0.0031, 0.0000, total_reward: 8.0, in 2.3423 secs\n",
      "Epoch: 500, mean_losses: 0.0026, 0.0000, total_reward: 9.0, in 2.4739 secs\n",
      "Epoch: 600, mean_losses: 0.0023, 0.0000, total_reward: 10.0, in 2.2023 secs\n",
      "Epoch: 700, mean_losses: 0.0020, 0.0000, total_reward: 9.0, in 2.4996 secs\n",
      "Epoch: 800, mean_losses: 0.0018, 0.0000, total_reward: 10.0, in 2.5489 secs\n",
      "Epoch: 900, mean_losses: 0.0017, 0.0000, total_reward: 10.0, in 2.6727 secs\n",
      "Epoch: 1000, mean_losses: 0.0015, 0.0000, total_reward: 10.0, in 2.4655 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 100 with reward 11.68\n",
      "\n",
      "# Training: Model 103\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.0137, 0.0000, total_reward: 9.0, in 3.0260 secs\n",
      "Epoch: 200, mean_losses: 0.0072, 0.0000, total_reward: 11.0, in 2.5978 secs\n",
      "Epoch: 300, mean_losses: 0.0048, 0.0000, total_reward: 13.0, in 2.7804 secs\n",
      "Epoch: 400, mean_losses: 0.0036, 0.0000, total_reward: 11.0, in 2.8132 secs\n",
      "Epoch: 500, mean_losses: 0.0028, 0.0000, total_reward: 12.0, in 3.1459 secs\n",
      "Epoch: 600, mean_losses: 0.0023, 0.0000, total_reward: 13.0, in 3.4575 secs\n",
      "Epoch: 700, mean_losses: 0.0019, 0.0000, total_reward: 16.0, in 3.2014 secs\n",
      "Epoch: 800, mean_losses: 0.0016, 0.0000, total_reward: 14.0, in 3.8112 secs\n",
      "Epoch: 900, mean_losses: 0.0014, 0.0000, total_reward: 12.0, in 4.4907 secs\n",
      "Epoch: 1000, mean_losses: 0.0012, 0.0000, total_reward: 18.0, in 5.9529 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 971 with reward 23.3\n",
      "\n",
      "# Training: Model 104\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.0259, 0.0000, total_reward: 8.0, in 2.6775 secs\n",
      "Epoch: 200, mean_losses: 0.0138, 0.0000, total_reward: 9.0, in 2.1302 secs\n",
      "Epoch: 300, mean_losses: 0.0094, 0.0000, total_reward: 8.0, in 2.1154 secs\n",
      "Epoch: 400, mean_losses: 0.0072, 0.0000, total_reward: 10.0, in 2.4000 secs\n",
      "Epoch: 500, mean_losses: 0.0058, 0.0000, total_reward: 9.0, in 2.2124 secs\n",
      "Epoch: 600, mean_losses: 0.0048, 0.0000, total_reward: 11.0, in 2.5201 secs\n",
      "Epoch: 700, mean_losses: 0.0042, 0.0000, total_reward: 9.0, in 2.2974 secs\n",
      "Epoch: 800, mean_losses: 0.0037, 0.0000, total_reward: 13.0, in 2.5848 secs\n",
      "Epoch: 900, mean_losses: 0.0033, 0.0000, total_reward: 9.0, in 2.2365 secs\n",
      "Epoch: 1000, mean_losses: 0.0030, 0.0000, total_reward: 10.0, in 2.3487 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 100 with reward 10.48\n",
      "\n",
      "# Training: Model 105\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.0002, 0.0000, total_reward: 24.0, in 2.9983 secs\n",
      "Epoch: 200, mean_losses: 0.0001, 0.0000, total_reward: 9.0, in 2.5986 secs\n",
      "Epoch: 300, mean_losses: 0.0001, 0.0000, total_reward: 9.0, in 2.2876 secs\n",
      "Epoch: 400, mean_losses: 0.0001, 0.0000, total_reward: 8.0, in 2.5846 secs\n",
      "Epoch: 500, mean_losses: 0.0000, 0.0000, total_reward: 10.0, in 2.2961 secs\n",
      "Epoch: 600, mean_losses: 0.0000, 0.0000, total_reward: 12.0, in 2.5404 secs\n",
      "Epoch: 700, mean_losses: 0.0000, 0.0000, total_reward: 10.0, in 2.3537 secs\n",
      "Epoch: 800, mean_losses: 0.0000, 0.0000, total_reward: 10.0, in 2.8309 secs\n",
      "Epoch: 900, mean_losses: 0.0000, 0.0000, total_reward: 11.0, in 2.2690 secs\n",
      "Epoch: 1000, mean_losses: 0.0000, 0.0000, total_reward: 12.0, in 2.3773 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 116 with reward 12.14\n",
      "\n",
      "# Training: Model 106\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.0124, 0.0000, total_reward: 16.0, in 3.4637 secs\n",
      "Epoch: 200, mean_losses: 0.0059, 0.0000, total_reward: 18.0, in 3.6202 secs\n",
      "Epoch: 300, mean_losses: 0.0038, 0.0000, total_reward: 17.0, in 3.9267 secs\n",
      "Epoch: 400, mean_losses: 0.0028, 0.0000, total_reward: 13.0, in 4.0778 secs\n",
      "Epoch: 500, mean_losses: 0.0018, 0.0000, total_reward: 35.0, in 7.3585 secs\n",
      "Epoch: 600, mean_losses: 0.0012, 0.0000, total_reward: 58.0, in 11.9220 secs\n",
      "Epoch: 700, mean_losses: 0.0009, 0.0000, total_reward: 10.0, in 12.9620 secs\n",
      "Epoch: 800, mean_losses: 0.0007, 0.0000, total_reward: 74.0, in 15.6657 secs\n",
      "Epoch: 900, mean_losses: 0.0005, 0.0000, total_reward: 15.0, in 14.3649 secs\n",
      "Epoch: 1000, mean_losses: 0.0005, 0.0000, total_reward: 70.0, in 16.5807 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 975 with reward 63.18\n",
      "\n",
      "# Training: Model 107\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.0019, 0.0000, total_reward: 10.0, in 2.6227 secs\n",
      "Epoch: 200, mean_losses: 0.0011, 0.0000, total_reward: 9.0, in 2.1305 secs\n",
      "Epoch: 300, mean_losses: 0.0007, 0.0000, total_reward: 10.0, in 2.2133 secs\n",
      "Epoch: 400, mean_losses: 0.0006, 0.0000, total_reward: 10.0, in 2.3848 secs\n",
      "Epoch: 500, mean_losses: 0.0005, 0.0000, total_reward: 10.0, in 2.1959 secs\n",
      "Epoch: 600, mean_losses: 0.0004, 0.0000, total_reward: 11.0, in 2.5213 secs\n",
      "Epoch: 700, mean_losses: 0.0003, 0.0000, total_reward: 9.0, in 2.5199 secs\n",
      "Epoch: 800, mean_losses: 0.0003, 0.0000, total_reward: 10.0, in 2.5959 secs\n",
      "Epoch: 900, mean_losses: 0.0003, 0.0000, total_reward: 10.0, in 2.5118 secs\n",
      "Epoch: 1000, mean_losses: 0.0002, 0.0000, total_reward: 10.0, in 2.6735 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 100 with reward 10.39\n",
      "\n",
      "# Training: Model 108\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.0008, 0.0000, total_reward: 8.0, in 2.5466 secs\n",
      "Epoch: 200, mean_losses: 0.0004, 0.0000, total_reward: 10.0, in 2.1630 secs\n",
      "Epoch: 300, mean_losses: 0.0003, 0.0000, total_reward: 10.0, in 2.1275 secs\n",
      "Epoch: 400, mean_losses: 0.0002, 0.0000, total_reward: 10.0, in 2.5012 secs\n",
      "Epoch: 500, mean_losses: 0.0002, 0.0000, total_reward: 9.0, in 2.2778 secs\n",
      "Epoch: 600, mean_losses: 0.0002, 0.0000, total_reward: 10.0, in 2.4814 secs\n",
      "Epoch: 700, mean_losses: 0.0001, 0.0000, total_reward: 10.0, in 2.2258 secs\n",
      "Epoch: 800, mean_losses: 0.0001, 0.0000, total_reward: 9.0, in 2.5261 secs\n",
      "Epoch: 900, mean_losses: 0.0001, 0.0000, total_reward: 9.0, in 2.3386 secs\n",
      "Epoch: 1000, mean_losses: 0.0001, 0.0000, total_reward: 9.0, in 2.3227 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 906 with reward 9.68\n",
      "\n",
      "# Training: Model 109\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.0012, 0.0000, total_reward: 21.0, in 4.0259 secs\n",
      "Epoch: 200, mean_losses: 0.0005, 0.0000, total_reward: 13.0, in 7.0857 secs\n",
      "Epoch: 300, mean_losses: 0.0002, 0.0000, total_reward: 79.0, in 10.7306 secs\n",
      "Epoch: 400, mean_losses: 0.0001, 0.0000, total_reward: 73.0, in 14.0586 secs\n",
      "Epoch: 500, mean_losses: 0.0001, 0.0000, total_reward: 81.0, in 18.6978 secs\n",
      "Epoch: 600, mean_losses: 0.0001, 0.0000, total_reward: 50.0, in 18.3595 secs\n",
      "Epoch: 700, mean_losses: 0.0001, 0.0000, total_reward: 55.0, in 22.0809 secs\n",
      "Epoch: 800, mean_losses: 0.0000, 0.0000, total_reward: 81.0, in 21.0850 secs\n",
      "Epoch: 900, mean_losses: 0.0000, 0.0000, total_reward: 35.0, in 19.9280 secs\n",
      "Epoch: 1000, mean_losses: 0.0000, 0.0000, total_reward: 65.0, in 21.2970 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 687 with reward 84.4\n",
      "\n",
      "# Training: Model 110\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.0179, 0.0000, total_reward: 10.0, in 2.4617 secs\n",
      "Epoch: 200, mean_losses: 0.0098, 0.0000, total_reward: 8.0, in 2.4091 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 300, mean_losses: 0.0068, 0.0000, total_reward: 8.0, in 2.2097 secs\n",
      "Epoch: 400, mean_losses: 0.0053, 0.0000, total_reward: 10.0, in 2.5402 secs\n",
      "Epoch: 500, mean_losses: 0.0044, 0.0000, total_reward: 9.0, in 2.3982 secs\n",
      "Epoch: 600, mean_losses: 0.0037, 0.0000, total_reward: 8.0, in 2.5030 secs\n",
      "Epoch: 700, mean_losses: 0.0032, 0.0000, total_reward: 9.0, in 2.1927 secs\n",
      "Epoch: 800, mean_losses: 0.0029, 0.0000, total_reward: 9.0, in 2.6984 secs\n",
      "Epoch: 900, mean_losses: 0.0026, 0.0000, total_reward: 9.0, in 2.5180 secs\n",
      "Epoch: 1000, mean_losses: 0.0024, 0.0000, total_reward: 9.0, in 2.3800 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 100 with reward 10.73\n",
      "\n",
      "# Training: Model 111\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.0196, 0.0000, total_reward: 10.0, in 2.6236 secs\n",
      "Epoch: 200, mean_losses: 0.0108, 0.0000, total_reward: 9.0, in 2.4337 secs\n",
      "Epoch: 300, mean_losses: 0.0076, 0.0000, total_reward: 10.0, in 2.2190 secs\n",
      "Epoch: 400, mean_losses: 0.0059, 0.0000, total_reward: 9.0, in 2.4261 secs\n",
      "Epoch: 500, mean_losses: 0.0048, 0.0000, total_reward: 8.0, in 2.1849 secs\n",
      "Epoch: 600, mean_losses: 0.0041, 0.0000, total_reward: 9.0, in 2.2436 secs\n",
      "Epoch: 700, mean_losses: 0.0036, 0.0000, total_reward: 9.0, in 2.4738 secs\n",
      "Epoch: 800, mean_losses: 0.0032, 0.0000, total_reward: 10.0, in 2.2000 secs\n",
      "Epoch: 900, mean_losses: 0.0029, 0.0000, total_reward: 8.0, in 2.5651 secs\n",
      "Epoch: 1000, mean_losses: 0.0026, 0.0000, total_reward: 9.0, in 2.3403 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 100 with reward 11.1\n",
      "\n",
      "# Training: Model 112\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.0000, 0.0000, total_reward: 105.0, in 13.6530 secs\n",
      "Epoch: 200, mean_losses: 0.0000, 0.0000, total_reward: 72.0, in 16.4328 secs\n",
      "Epoch: 300, mean_losses: 0.0000, 0.0000, total_reward: 52.0, in 15.9563 secs\n",
      "Epoch: 400, mean_losses: 0.0000, 0.0000, total_reward: 66.0, in 17.0010 secs\n",
      "Epoch: 500, mean_losses: 0.0000, 0.0000, total_reward: 71.0, in 17.2700 secs\n",
      "Epoch: 600, mean_losses: 0.0000, 0.0000, total_reward: 64.0, in 17.3338 secs\n",
      "Epoch: 700, mean_losses: 0.0000, 0.0000, total_reward: 72.0, in 17.2975 secs\n",
      "Epoch: 800, mean_losses: 0.0000, 0.0000, total_reward: 58.0, in 17.5244 secs\n",
      "Epoch: 900, mean_losses: 0.0000, 0.0000, total_reward: 61.0, in 18.8437 secs\n",
      "Epoch: 1000, mean_losses: 0.0000, 0.0000, total_reward: 51.0, in 18.1487 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 547 with reward 68.59\n",
      "\n",
      "# Training: Model 113\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.0006, 0.0000, total_reward: 80.0, in 23.5152 secs\n",
      "Epoch: 200, mean_losses: 0.0003, 0.0000, total_reward: 160.0, in 27.7595 secs\n",
      "Epoch: 300, mean_losses: 0.0002, 0.0000, total_reward: 100.0, in 27.4392 secs\n",
      "Epoch: 400, mean_losses: 0.0002, 0.0000, total_reward: 67.0, in 25.1254 secs\n",
      "Epoch: 500, mean_losses: 0.0001, 0.0000, total_reward: 79.0, in 32.5586 secs\n",
      "Epoch: 600, mean_losses: 0.0001, 0.0000, total_reward: 78.0, in 28.0919 secs\n",
      "Epoch: 700, mean_losses: 0.0001, 0.0000, total_reward: 170.0, in 28.9176 secs\n",
      "Epoch: 800, mean_losses: 0.0001, 0.0000, total_reward: 68.0, in 27.8482 secs\n",
      "Epoch: 900, mean_losses: 0.0001, 0.0000, total_reward: 68.0, in 26.3911 secs\n",
      "Epoch: 1000, mean_losses: 0.0001, 0.0000, total_reward: 63.0, in 27.4049 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 502 with reward 120.35\n",
      "\n",
      "# Training: Model 114\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.0104, 0.0000, total_reward: 9.0, in 2.1866 secs\n",
      "Epoch: 200, mean_losses: 0.0058, 0.0000, total_reward: 10.0, in 2.3325 secs\n",
      "Epoch: 300, mean_losses: 0.0042, 0.0000, total_reward: 10.0, in 2.1686 secs\n",
      "Epoch: 400, mean_losses: 0.0033, 0.0000, total_reward: 9.0, in 2.4386 secs\n",
      "Epoch: 500, mean_losses: 0.0028, 0.0000, total_reward: 9.0, in 2.2871 secs\n",
      "Epoch: 600, mean_losses: 0.0024, 0.0000, total_reward: 10.0, in 2.4849 secs\n",
      "Epoch: 700, mean_losses: 0.0022, 0.0000, total_reward: 9.0, in 2.5659 secs\n",
      "Epoch: 800, mean_losses: 0.0020, 0.0000, total_reward: 9.0, in 2.4014 secs\n",
      "Epoch: 900, mean_losses: 0.0018, 0.0000, total_reward: 10.0, in 2.8859 secs\n",
      "Epoch: 1000, mean_losses: 0.0017, 0.0000, total_reward: 10.0, in 2.6711 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 100 with reward 9.61\n",
      "\n",
      "# Training: Model 115\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.0001, 0.0000, total_reward: 8.0, in 2.6344 secs\n",
      "Epoch: 200, mean_losses: 0.0000, 0.0000, total_reward: 10.0, in 2.5305 secs\n",
      "Epoch: 300, mean_losses: 0.0000, 0.0000, total_reward: 10.0, in 2.3280 secs\n",
      "Epoch: 400, mean_losses: 0.0000, 0.0000, total_reward: 12.0, in 2.6208 secs\n",
      "Epoch: 500, mean_losses: 0.0000, 0.0000, total_reward: 10.0, in 2.9359 secs\n",
      "Epoch: 600, mean_losses: 0.0000, 0.0000, total_reward: 10.0, in 2.5360 secs\n",
      "Epoch: 700, mean_losses: 0.0000, 0.0000, total_reward: 8.0, in 2.3443 secs\n",
      "Epoch: 800, mean_losses: 0.0000, 0.0000, total_reward: 8.0, in 2.5777 secs\n",
      "Epoch: 900, mean_losses: 0.0000, 0.0000, total_reward: 9.0, in 2.4526 secs\n",
      "Epoch: 1000, mean_losses: 0.0000, 0.0000, total_reward: 10.0, in 3.3357 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 489 with reward 12.33\n",
      "\n",
      "# Training: Model 116\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.0008, 0.0000, total_reward: 99.0, in 16.6537 secs\n",
      "Epoch: 200, mean_losses: 0.0003, 0.0000, total_reward: 79.0, in 25.2626 secs\n",
      "Epoch: 300, mean_losses: 0.0002, 0.0000, total_reward: 200.0, in 37.2810 secs\n",
      "Epoch: 400, mean_losses: 0.0001, 0.0000, total_reward: 63.0, in 38.3769 secs\n",
      "Epoch: 500, mean_losses: 0.0001, 0.0000, total_reward: 81.0, in 39.8121 secs\n",
      "Epoch: 600, mean_losses: 0.0001, 0.0000, total_reward: 74.0, in 39.4400 secs\n",
      "Epoch: 700, mean_losses: 0.0001, 0.0000, total_reward: 183.0, in 41.2516 secs\n",
      "Epoch: 800, mean_losses: 0.0001, 0.0000, total_reward: 174.0, in 40.2011 secs\n",
      "Epoch: 900, mean_losses: 0.0000, 0.0000, total_reward: 77.0, in 40.5255 secs\n",
      "Epoch: 1000, mean_losses: 0.0000, 0.0000, total_reward: 150.0, in 42.7350 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 939 with reward 155.06\n",
      "\n",
      "# Training: Model 117\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.0039, 0.0000, total_reward: 10.0, in 2.6224 secs\n",
      "Epoch: 200, mean_losses: 0.0021, 0.0000, total_reward: 10.0, in 2.7443 secs\n",
      "Epoch: 300, mean_losses: 0.0014, 0.0000, total_reward: 12.0, in 2.4808 secs\n",
      "Epoch: 400, mean_losses: 0.0011, 0.0000, total_reward: 10.0, in 2.7961 secs\n",
      "Epoch: 500, mean_losses: 0.0009, 0.0000, total_reward: 10.0, in 2.7741 secs\n",
      "Epoch: 600, mean_losses: 0.0007, 0.0000, total_reward: 8.0, in 2.8081 secs\n",
      "Epoch: 700, mean_losses: 0.0006, 0.0000, total_reward: 9.0, in 2.9453 secs\n",
      "Epoch: 800, mean_losses: 0.0006, 0.0000, total_reward: 10.0, in 3.0584 secs\n",
      "Epoch: 900, mean_losses: 0.0005, 0.0000, total_reward: 11.0, in 2.4008 secs\n",
      "Epoch: 1000, mean_losses: 0.0004, 0.0000, total_reward: 10.0, in 2.5329 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 101 with reward 10.92\n",
      "\n",
      "# Training: Model 118\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.0170, 0.0000, total_reward: 27.0, in 3.7769 secs\n",
      "Epoch: 200, mean_losses: 0.0050, 0.0000, total_reward: 27.0, in 7.8381 secs\n",
      "Epoch: 300, mean_losses: 0.0033, 0.0000, total_reward: 13.0, in 6.1544 secs\n",
      "Epoch: 400, mean_losses: 0.0025, 0.0000, total_reward: 24.0, in 6.6529 secs\n",
      "Epoch: 500, mean_losses: 0.0020, 0.0000, total_reward: 37.0, in 6.9752 secs\n",
      "Epoch: 600, mean_losses: 0.0017, 0.0000, total_reward: 18.0, in 6.7627 secs\n",
      "Epoch: 700, mean_losses: 0.0014, 0.0000, total_reward: 41.0, in 6.9655 secs\n",
      "Epoch: 800, mean_losses: 0.0012, 0.0000, total_reward: 36.0, in 7.3641 secs\n",
      "Epoch: 900, mean_losses: 0.0011, 0.0000, total_reward: 37.0, in 6.8860 secs\n",
      "Epoch: 1000, mean_losses: 0.0010, 0.0000, total_reward: 12.0, in 7.4581 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 195 with reward 33.46\n",
      "\n",
      "# Training: Model 119\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.0037, 0.0000, total_reward: 9.0, in 3.0573 secs\n",
      "Epoch: 200, mean_losses: 0.0020, 0.0000, total_reward: 8.0, in 2.4491 secs\n",
      "Epoch: 300, mean_losses: 0.0014, 0.0000, total_reward: 9.0, in 2.7370 secs\n",
      "Epoch: 400, mean_losses: 0.0011, 0.0000, total_reward: 10.0, in 2.7408 secs\n",
      "Epoch: 500, mean_losses: 0.0009, 0.0000, total_reward: 9.0, in 2.7398 secs\n",
      "Epoch: 600, mean_losses: 0.0007, 0.0000, total_reward: 9.0, in 2.3439 secs\n",
      "Epoch: 700, mean_losses: 0.0006, 0.0000, total_reward: 10.0, in 2.7738 secs\n",
      "Epoch: 800, mean_losses: 0.0006, 0.0000, total_reward: 10.0, in 2.4808 secs\n",
      "Epoch: 900, mean_losses: 0.0005, 0.0000, total_reward: 10.0, in 2.7548 secs\n",
      "Epoch: 1000, mean_losses: 0.0004, 0.0000, total_reward: 9.0, in 2.4787 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 108 with reward 11.92\n",
      "\n",
      "# Training: Model 120\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.0016, 0.0000, total_reward: 8.0, in 4.4708 secs\n",
      "Epoch: 200, mean_losses: 0.0009, 0.0000, total_reward: 10.0, in 2.5089 secs\n",
      "Epoch: 300, mean_losses: 0.0006, 0.0000, total_reward: 10.0, in 2.3189 secs\n",
      "Epoch: 400, mean_losses: 0.0005, 0.0000, total_reward: 9.0, in 2.6080 secs\n",
      "Epoch: 500, mean_losses: 0.0004, 0.0000, total_reward: 11.0, in 2.2063 secs\n",
      "Epoch: 600, mean_losses: 0.0003, 0.0000, total_reward: 9.0, in 3.0572 secs\n",
      "Epoch: 700, mean_losses: 0.0003, 0.0000, total_reward: 10.0, in 2.3845 secs\n",
      "Epoch: 800, mean_losses: 0.0003, 0.0000, total_reward: 9.0, in 2.5495 secs\n",
      "Epoch: 900, mean_losses: 0.0002, 0.0000, total_reward: 10.0, in 2.4412 secs\n",
      "Epoch: 1000, mean_losses: 0.0002, 0.0000, total_reward: 10.0, in 2.5027 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 100 with reward 11.58\n",
      "\n",
      "# Training: Model 121\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.0046, 0.0000, total_reward: 10.0, in 3.0998 secs\n",
      "Epoch: 200, mean_losses: 0.0025, 0.0000, total_reward: 10.0, in 2.3159 secs\n",
      "Epoch: 300, mean_losses: 0.0017, 0.0000, total_reward: 9.0, in 2.8498 secs\n",
      "Epoch: 400, mean_losses: 0.0013, 0.0000, total_reward: 10.0, in 2.2698 secs\n",
      "Epoch: 500, mean_losses: 0.0011, 0.0000, total_reward: 10.0, in 2.6394 secs\n",
      "Epoch: 600, mean_losses: 0.0009, 0.0000, total_reward: 9.0, in 2.4573 secs\n",
      "Epoch: 700, mean_losses: 0.0008, 0.0000, total_reward: 14.0, in 2.6866 secs\n",
      "Epoch: 800, mean_losses: 0.0007, 0.0000, total_reward: 9.0, in 2.3311 secs\n",
      "Epoch: 900, mean_losses: 0.0006, 0.0000, total_reward: 10.0, in 2.5809 secs\n",
      "Epoch: 1000, mean_losses: 0.0006, 0.0000, total_reward: 13.0, in 2.3669 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 100 with reward 11.73\n",
      "\n",
      "# Training: Model 122\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.0004, 0.0000, total_reward: 9.0, in 4.6989 secs\n",
      "Epoch: 200, mean_losses: 0.0002, 0.0000, total_reward: 10.0, in 3.8030 secs\n",
      "Epoch: 300, mean_losses: 0.0001, 0.0000, total_reward: 21.0, in 3.7588 secs\n",
      "Epoch: 400, mean_losses: 0.0001, 0.0000, total_reward: 18.0, in 3.1221 secs\n",
      "Epoch: 500, mean_losses: 0.0001, 0.0000, total_reward: 11.0, in 3.6110 secs\n",
      "Epoch: 600, mean_losses: 0.0001, 0.0000, total_reward: 12.0, in 3.3283 secs\n",
      "Epoch: 700, mean_losses: 0.0001, 0.0000, total_reward: 11.0, in 3.4622 secs\n",
      "Epoch: 800, mean_losses: 0.0001, 0.0000, total_reward: 11.0, in 3.4266 secs\n",
      "Epoch: 900, mean_losses: 0.0001, 0.0000, total_reward: 16.0, in 3.2742 secs\n",
      "Epoch: 1000, mean_losses: 0.0001, 0.0000, total_reward: 16.0, in 3.3951 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 100 with reward 19.27\n",
      "\n",
      "# Training: Model 123\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.0049, 0.0000, total_reward: 36.0, in 10.2970 secs\n",
      "Epoch: 200, mean_losses: 0.0020, 0.0000, total_reward: 13.0, in 16.4645 secs\n",
      "Epoch: 300, mean_losses: 0.0011, 0.0000, total_reward: 48.0, in 22.2385 secs\n",
      "Epoch: 400, mean_losses: 0.0008, 0.0000, total_reward: 123.0, in 21.1682 secs\n",
      "Epoch: 500, mean_losses: 0.0006, 0.0000, total_reward: 92.0, in 26.8331 secs\n",
      "Epoch: 600, mean_losses: 0.0004, 0.0000, total_reward: 59.0, in 29.0402 secs\n",
      "Epoch: 700, mean_losses: 0.0003, 0.0000, total_reward: 41.0, in 33.8444 secs\n",
      "Epoch: 800, mean_losses: 0.0003, 0.0000, total_reward: 83.0, in 30.0031 secs\n",
      "Epoch: 900, mean_losses: 0.0003, 0.0000, total_reward: 180.0, in 30.6802 secs\n",
      "Epoch: 1000, mean_losses: 0.0002, 0.0000, total_reward: 84.0, in 31.9629 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 695 with reward 125.33\n",
      "\n",
      "# Training: Model 124\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.0021, 0.0000, total_reward: 13.0, in 6.4920 secs\n",
      "Epoch: 200, mean_losses: 0.0014, 0.0000, total_reward: 12.0, in 3.2575 secs\n",
      "Epoch: 300, mean_losses: 0.0011, 0.0000, total_reward: 9.0, in 3.2990 secs\n",
      "Epoch: 400, mean_losses: 0.0009, 0.0000, total_reward: 10.0, in 2.6864 secs\n",
      "Epoch: 500, mean_losses: 0.0008, 0.0000, total_reward: 10.0, in 2.9481 secs\n",
      "Epoch: 600, mean_losses: 0.0007, 0.0000, total_reward: 8.0, in 2.3922 secs\n",
      "Epoch: 700, mean_losses: 0.0006, 0.0000, total_reward: 10.0, in 2.5657 secs\n",
      "Epoch: 800, mean_losses: 0.0006, 0.0000, total_reward: 10.0, in 2.4235 secs\n",
      "Epoch: 900, mean_losses: 0.0005, 0.0000, total_reward: 14.0, in 2.8347 secs\n",
      "Epoch: 1000, mean_losses: 0.0005, 0.0000, total_reward: 10.0, in 2.6243 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 115 with reward 28.25\n",
      "\n",
      "# Training: Model 125\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.0212, 0.0000, total_reward: 9.0, in 2.6348 secs\n",
      "Epoch: 200, mean_losses: 0.0115, 0.0000, total_reward: 10.0, in 2.5058 secs\n",
      "Epoch: 300, mean_losses: 0.0079, 0.0000, total_reward: 10.0, in 2.4471 secs\n",
      "Epoch: 400, mean_losses: 0.0060, 0.0000, total_reward: 9.0, in 2.7806 secs\n",
      "Epoch: 500, mean_losses: 0.0049, 0.0000, total_reward: 10.0, in 2.5090 secs\n",
      "Epoch: 600, mean_losses: 0.0041, 0.0000, total_reward: 9.0, in 2.7504 secs\n",
      "Epoch: 700, mean_losses: 0.0035, 0.0000, total_reward: 9.0, in 2.4528 secs\n",
      "Epoch: 800, mean_losses: 0.0031, 0.0000, total_reward: 9.0, in 2.7415 secs\n",
      "Epoch: 900, mean_losses: 0.0028, 0.0000, total_reward: 10.0, in 2.5351 secs\n",
      "Epoch: 1000, mean_losses: 0.0025, 0.0000, total_reward: 8.0, in 2.8691 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 100 with reward 10.76\n",
      "\n",
      "# Training: Model 126\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.0060, 0.0000, total_reward: 23.0, in 9.6529 secs\n",
      "Epoch: 200, mean_losses: 0.0035, 0.0000, total_reward: 40.0, in 7.9773 secs\n",
      "Epoch: 300, mean_losses: 0.0028, 0.0000, total_reward: 13.0, in 4.2050 secs\n",
      "Epoch: 400, mean_losses: 0.0024, 0.0000, total_reward: 22.0, in 4.0054 secs\n",
      "Epoch: 500, mean_losses: 0.0021, 0.0000, total_reward: 18.0, in 3.6386 secs\n",
      "Epoch: 600, mean_losses: 0.0019, 0.0000, total_reward: 8.0, in 3.4938 secs\n",
      "Epoch: 700, mean_losses: 0.0017, 0.0000, total_reward: 13.0, in 3.5312 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 800, mean_losses: 0.0016, 0.0000, total_reward: 11.0, in 3.7001 secs\n",
      "Epoch: 900, mean_losses: 0.0014, 0.0000, total_reward: 22.0, in 3.3967 secs\n",
      "Epoch: 1000, mean_losses: 0.0013, 0.0000, total_reward: 11.0, in 3.7367 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 104 with reward 40.09\n",
      "\n",
      "# Training: Model 127\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.0011, 0.0000, total_reward: 15.0, in 3.0049 secs\n",
      "Epoch: 200, mean_losses: 0.0006, 0.0000, total_reward: 9.0, in 2.9733 secs\n",
      "Epoch: 300, mean_losses: 0.0004, 0.0000, total_reward: 8.0, in 2.3458 secs\n",
      "Epoch: 400, mean_losses: 0.0003, 0.0000, total_reward: 10.0, in 3.8572 secs\n",
      "Epoch: 500, mean_losses: 0.0003, 0.0000, total_reward: 10.0, in 2.4038 secs\n",
      "Epoch: 600, mean_losses: 0.0002, 0.0000, total_reward: 9.0, in 2.2601 secs\n",
      "Epoch: 700, mean_losses: 0.0002, 0.0000, total_reward: 8.0, in 2.5548 secs\n",
      "Epoch: 800, mean_losses: 0.0002, 0.0000, total_reward: 8.0, in 2.3099 secs\n",
      "Epoch: 900, mean_losses: 0.0002, 0.0000, total_reward: 10.0, in 2.6595 secs\n",
      "Epoch: 1000, mean_losses: 0.0002, 0.0000, total_reward: 9.0, in 2.4081 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 118 with reward 13.26\n",
      "\n",
      "# Training: Model 128\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.0149, 0.0000, total_reward: 10.0, in 4.4667 secs\n",
      "Epoch: 200, mean_losses: 0.0095, 0.0000, total_reward: 13.0, in 2.7724 secs\n",
      "Epoch: 300, mean_losses: 0.0071, 0.0000, total_reward: 10.0, in 2.4608 secs\n",
      "Epoch: 400, mean_losses: 0.0057, 0.0000, total_reward: 10.0, in 2.8652 secs\n",
      "Epoch: 500, mean_losses: 0.0048, 0.0000, total_reward: 10.0, in 2.4046 secs\n",
      "Epoch: 600, mean_losses: 0.0041, 0.0000, total_reward: 10.0, in 2.7419 secs\n",
      "Epoch: 700, mean_losses: 0.0036, 0.0000, total_reward: 9.0, in 2.5039 secs\n",
      "Epoch: 800, mean_losses: 0.0032, 0.0000, total_reward: 10.0, in 2.6073 secs\n",
      "Epoch: 900, mean_losses: 0.0029, 0.0000, total_reward: 9.0, in 2.5382 secs\n",
      "Epoch: 1000, mean_losses: 0.0026, 0.0000, total_reward: 10.0, in 2.8427 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 118 with reward 19.0\n",
      "\n",
      "# Training: Model 129\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.0031, 0.0000, total_reward: 9.0, in 2.4302 secs\n",
      "Epoch: 200, mean_losses: 0.0017, 0.0000, total_reward: 9.0, in 2.6177 secs\n",
      "Epoch: 300, mean_losses: 0.0012, 0.0000, total_reward: 9.0, in 2.2520 secs\n",
      "Epoch: 400, mean_losses: 0.0009, 0.0000, total_reward: 8.0, in 2.7826 secs\n",
      "Epoch: 500, mean_losses: 0.0008, 0.0000, total_reward: 9.0, in 2.4058 secs\n",
      "Epoch: 600, mean_losses: 0.0007, 0.0000, total_reward: 10.0, in 2.5736 secs\n",
      "Epoch: 700, mean_losses: 0.0006, 0.0000, total_reward: 9.0, in 2.4064 secs\n",
      "Epoch: 800, mean_losses: 0.0005, 0.0000, total_reward: 10.0, in 2.5082 secs\n",
      "Epoch: 900, mean_losses: 0.0005, 0.0000, total_reward: 9.0, in 2.3872 secs\n",
      "Epoch: 1000, mean_losses: 0.0004, 0.0000, total_reward: 10.0, in 2.4014 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 100 with reward 10.54\n",
      "\n",
      "# Training: Model 130\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.0187, 0.0000, total_reward: 9.0, in 2.2629 secs\n",
      "Epoch: 200, mean_losses: 0.0095, 0.0000, total_reward: 8.0, in 2.4807 secs\n",
      "Epoch: 300, mean_losses: 0.0064, 0.0000, total_reward: 8.0, in 2.3450 secs\n",
      "Epoch: 400, mean_losses: 0.0048, 0.0000, total_reward: 8.0, in 2.6712 secs\n",
      "Epoch: 500, mean_losses: 0.0039, 0.0000, total_reward: 11.0, in 2.3447 secs\n",
      "Epoch: 600, mean_losses: 0.0032, 0.0000, total_reward: 9.0, in 2.5055 secs\n",
      "Epoch: 700, mean_losses: 0.0028, 0.0000, total_reward: 10.0, in 2.6742 secs\n",
      "Epoch: 800, mean_losses: 0.0024, 0.0000, total_reward: 8.0, in 2.2910 secs\n",
      "Epoch: 900, mean_losses: 0.0022, 0.0000, total_reward: 10.0, in 2.6040 secs\n",
      "Epoch: 1000, mean_losses: 0.0019, 0.0000, total_reward: 8.0, in 2.5411 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 100 with reward 9.71\n",
      "\n",
      "# Training: Model 131\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.0006, 0.0000, total_reward: 21.0, in 4.5840 secs\n",
      "Epoch: 200, mean_losses: 0.0003, 0.0000, total_reward: 33.0, in 4.3919 secs\n",
      "Epoch: 300, mean_losses: 0.0002, 0.0000, total_reward: 18.0, in 3.3684 secs\n",
      "Epoch: 400, mean_losses: 0.0002, 0.0000, total_reward: 17.0, in 2.8145 secs\n",
      "Epoch: 500, mean_losses: 0.0002, 0.0000, total_reward: 13.0, in 3.2828 secs\n",
      "Epoch: 600, mean_losses: 0.0001, 0.0000, total_reward: 9.0, in 2.7016 secs\n",
      "Epoch: 700, mean_losses: 0.0001, 0.0000, total_reward: 9.0, in 2.8698 secs\n",
      "Epoch: 800, mean_losses: 0.0001, 0.0000, total_reward: 11.0, in 2.6724 secs\n",
      "Epoch: 900, mean_losses: 0.0001, 0.0000, total_reward: 10.0, in 3.0748 secs\n",
      "Epoch: 1000, mean_losses: 0.0001, 0.0000, total_reward: 14.0, in 2.6987 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 100 with reward 19.82\n",
      "\n",
      "# Training: Model 132\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.0040, 0.0000, total_reward: 9.0, in 2.2239 secs\n",
      "Epoch: 200, mean_losses: 0.0020, 0.0000, total_reward: 8.0, in 2.4999 secs\n",
      "Epoch: 300, mean_losses: 0.0012, 0.0000, total_reward: 23.0, in 2.8638 secs\n",
      "Epoch: 400, mean_losses: 0.0007, 0.0000, total_reward: 10.0, in 5.8471 secs\n",
      "Epoch: 500, mean_losses: 0.0006, 0.0000, total_reward: 10.0, in 2.5489 secs\n",
      "Epoch: 600, mean_losses: 0.0005, 0.0000, total_reward: 10.0, in 2.2494 secs\n",
      "Epoch: 700, mean_losses: 0.0005, 0.0000, total_reward: 9.0, in 2.6112 secs\n",
      "Epoch: 800, mean_losses: 0.0004, 0.0000, total_reward: 9.0, in 2.7479 secs\n",
      "Epoch: 900, mean_losses: 0.0004, 0.0000, total_reward: 8.0, in 2.4155 secs\n",
      "Epoch: 1000, mean_losses: 0.0004, 0.0000, total_reward: 8.0, in 2.6650 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 344 with reward 23.51\n",
      "\n",
      "# Training: Model 133\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.0096, 0.0000, total_reward: 9.0, in 2.2782 secs\n",
      "Epoch: 200, mean_losses: 0.0050, 0.0000, total_reward: 8.0, in 2.6005 secs\n",
      "Epoch: 300, mean_losses: 0.0034, 0.0000, total_reward: 9.0, in 2.6297 secs\n",
      "Epoch: 400, mean_losses: 0.0026, 0.0000, total_reward: 8.0, in 2.4707 secs\n",
      "Epoch: 500, mean_losses: 0.0021, 0.0000, total_reward: 9.0, in 2.5055 secs\n",
      "Epoch: 600, mean_losses: 0.0017, 0.0000, total_reward: 10.0, in 2.2116 secs\n",
      "Epoch: 700, mean_losses: 0.0015, 0.0000, total_reward: 9.0, in 2.6175 secs\n",
      "Epoch: 800, mean_losses: 0.0013, 0.0000, total_reward: 10.0, in 2.2709 secs\n",
      "Epoch: 900, mean_losses: 0.0012, 0.0000, total_reward: 10.0, in 2.8276 secs\n",
      "Epoch: 1000, mean_losses: 0.0011, 0.0000, total_reward: 10.0, in 2.3182 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 100 with reward 9.82\n",
      "\n",
      "# Training: Model 134\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.0042, 0.0000, total_reward: 37.0, in 8.5309 secs\n",
      "Epoch: 200, mean_losses: 0.0018, 0.0000, total_reward: 40.0, in 11.7466 secs\n",
      "Epoch: 300, mean_losses: 0.0011, 0.0000, total_reward: 39.0, in 14.0045 secs\n",
      "Epoch: 400, mean_losses: 0.0008, 0.0000, total_reward: 84.0, in 13.0769 secs\n",
      "Epoch: 500, mean_losses: 0.0006, 0.0000, total_reward: 52.0, in 14.2046 secs\n",
      "Epoch: 600, mean_losses: 0.0005, 0.0000, total_reward: 32.0, in 14.2792 secs\n",
      "Epoch: 700, mean_losses: 0.0004, 0.0000, total_reward: 39.0, in 14.2830 secs\n",
      "Epoch: 800, mean_losses: 0.0004, 0.0000, total_reward: 73.0, in 14.6960 secs\n",
      "Epoch: 900, mean_losses: 0.0003, 0.0000, total_reward: 30.0, in 14.3009 secs\n",
      "Epoch: 1000, mean_losses: 0.0003, 0.0000, total_reward: 41.0, in 14.0994 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 765 with reward 56.56\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Training: Model 135\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.0154, 0.0000, total_reward: 10.0, in 2.3663 secs\n",
      "Epoch: 200, mean_losses: 0.0083, 0.0000, total_reward: 11.0, in 2.5028 secs\n",
      "Epoch: 300, mean_losses: 0.0058, 0.0000, total_reward: 10.0, in 2.1434 secs\n",
      "Epoch: 400, mean_losses: 0.0045, 0.0000, total_reward: 10.0, in 2.1437 secs\n",
      "Epoch: 500, mean_losses: 0.0037, 0.0000, total_reward: 10.0, in 2.5037 secs\n",
      "Epoch: 600, mean_losses: 0.0032, 0.0000, total_reward: 10.0, in 2.2527 secs\n",
      "Epoch: 700, mean_losses: 0.0028, 0.0000, total_reward: 9.0, in 2.5427 secs\n",
      "Epoch: 800, mean_losses: 0.0025, 0.0000, total_reward: 10.0, in 2.3149 secs\n",
      "Epoch: 900, mean_losses: 0.0023, 0.0000, total_reward: 10.0, in 2.6310 secs\n",
      "Epoch: 1000, mean_losses: 0.0021, 0.0000, total_reward: 8.0, in 2.6125 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 100 with reward 10.17\n",
      "\n",
      "# Training: Model 136\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.0075, 0.0000, total_reward: 9.0, in 2.7943 secs\n",
      "Epoch: 200, mean_losses: 0.0042, 0.0000, total_reward: 9.0, in 2.1746 secs\n",
      "Epoch: 300, mean_losses: 0.0030, 0.0000, total_reward: 10.0, in 2.5024 secs\n",
      "Epoch: 400, mean_losses: 0.0023, 0.0000, total_reward: 10.0, in 3.1084 secs\n",
      "Epoch: 500, mean_losses: 0.0019, 0.0000, total_reward: 10.0, in 2.6018 secs\n",
      "Epoch: 600, mean_losses: 0.0016, 0.0000, total_reward: 10.0, in 2.3851 secs\n",
      "Epoch: 700, mean_losses: 0.0014, 0.0000, total_reward: 9.0, in 2.5703 secs\n",
      "Epoch: 800, mean_losses: 0.0012, 0.0000, total_reward: 10.0, in 2.2627 secs\n",
      "Epoch: 900, mean_losses: 0.0011, 0.0000, total_reward: 10.0, in 2.7109 secs\n",
      "Epoch: 1000, mean_losses: 0.0010, 0.0000, total_reward: 10.0, in 2.4941 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 100 with reward 11.83\n",
      "\n",
      "# Training: Model 137\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.0007, 0.0000, total_reward: 36.0, in 13.1344 secs\n",
      "Epoch: 200, mean_losses: 0.0005, 0.0000, total_reward: 15.0, in 6.4935 secs\n",
      "Epoch: 300, mean_losses: 0.0004, 0.0000, total_reward: 10.0, in 3.1896 secs\n",
      "Epoch: 400, mean_losses: 0.0004, 0.0000, total_reward: 10.0, in 2.5759 secs\n",
      "Epoch: 500, mean_losses: 0.0004, 0.0000, total_reward: 10.0, in 2.9142 secs\n",
      "Epoch: 600, mean_losses: 0.0003, 0.0000, total_reward: 9.0, in 2.4749 secs\n",
      "Epoch: 700, mean_losses: 0.0003, 0.0000, total_reward: 11.0, in 2.7519 secs\n",
      "Epoch: 800, mean_losses: 0.0003, 0.0000, total_reward: 9.0, in 2.5216 secs\n",
      "Epoch: 900, mean_losses: 0.0003, 0.0000, total_reward: 10.0, in 2.7729 secs\n",
      "Epoch: 1000, mean_losses: 0.0003, 0.0000, total_reward: 8.0, in 2.4859 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 106 with reward 55.31\n",
      "\n",
      "# Training: Model 138\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.0168, 0.0000, total_reward: 10.0, in 2.5967 secs\n",
      "Epoch: 200, mean_losses: 0.0086, 0.0000, total_reward: 10.0, in 2.2386 secs\n",
      "Epoch: 300, mean_losses: 0.0059, 0.0000, total_reward: 10.0, in 2.4466 secs\n",
      "Epoch: 400, mean_losses: 0.0045, 0.0000, total_reward: 10.0, in 2.3370 secs\n",
      "Epoch: 500, mean_losses: 0.0036, 0.0000, total_reward: 10.0, in 2.4296 secs\n",
      "Epoch: 600, mean_losses: 0.0030, 0.0000, total_reward: 10.0, in 2.6773 secs\n",
      "Epoch: 700, mean_losses: 0.0026, 0.0000, total_reward: 9.0, in 2.3493 secs\n",
      "Epoch: 800, mean_losses: 0.0023, 0.0000, total_reward: 10.0, in 2.6578 secs\n",
      "Epoch: 900, mean_losses: 0.0021, 0.0000, total_reward: 9.0, in 2.2020 secs\n",
      "Epoch: 1000, mean_losses: 0.0019, 0.0000, total_reward: 9.0, in 2.6685 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 692 with reward 9.75\n",
      "\n",
      "# Training: Model 139\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.0026, 0.0000, total_reward: 13.0, in 2.9582 secs\n",
      "Epoch: 200, mean_losses: 0.0013, 0.0000, total_reward: 13.0, in 2.5457 secs\n",
      "Epoch: 300, mean_losses: 0.0009, 0.0000, total_reward: 13.0, in 2.7552 secs\n",
      "Epoch: 400, mean_losses: 0.0007, 0.0000, total_reward: 10.0, in 2.4762 secs\n",
      "Epoch: 500, mean_losses: 0.0005, 0.0000, total_reward: 26.0, in 3.4593 secs\n",
      "Epoch: 600, mean_losses: 0.0004, 0.0000, total_reward: 10.0, in 3.4969 secs\n",
      "Epoch: 700, mean_losses: 0.0004, 0.0000, total_reward: 19.0, in 3.5697 secs\n",
      "Epoch: 800, mean_losses: 0.0003, 0.0000, total_reward: 14.0, in 3.3222 secs\n",
      "Epoch: 900, mean_losses: 0.0003, 0.0000, total_reward: 15.0, in 3.3060 secs\n",
      "Epoch: 1000, mean_losses: 0.0002, 0.0000, total_reward: 11.0, in 3.5028 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 527 with reward 14.66\n",
      "\n",
      "# Training: Model 140\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.0111, 0.0000, total_reward: 8.0, in 2.9657 secs\n",
      "Epoch: 200, mean_losses: 0.0050, 0.0000, total_reward: 10.0, in 3.2135 secs\n",
      "Epoch: 300, mean_losses: 0.0022, 0.0000, total_reward: 37.0, in 8.7997 secs\n",
      "Epoch: 400, mean_losses: 0.0019, 0.0000, total_reward: 8.0, in 2.5568 secs\n",
      "Epoch: 500, mean_losses: 0.0017, 0.0000, total_reward: 9.0, in 2.6077 secs\n",
      "Epoch: 600, mean_losses: 0.0015, 0.0000, total_reward: 9.0, in 2.3003 secs\n",
      "Epoch: 700, mean_losses: 0.0014, 0.0000, total_reward: 9.0, in 2.5914 secs\n",
      "Epoch: 800, mean_losses: 0.0012, 0.0000, total_reward: 10.0, in 2.3766 secs\n",
      "Epoch: 900, mean_losses: 0.0012, 0.0000, total_reward: 9.0, in 2.6684 secs\n",
      "Epoch: 1000, mean_losses: 0.0011, 0.0000, total_reward: 11.0, in 2.3957 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 302 with reward 34.6\n",
      "\n",
      "# Training: Model 141\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.0002, 0.0000, total_reward: 12.0, in 2.8238 secs\n",
      "Epoch: 200, mean_losses: 0.0001, 0.0000, total_reward: 20.0, in 3.1635 secs\n",
      "Epoch: 300, mean_losses: 0.0000, 0.0000, total_reward: 15.0, in 5.9456 secs\n",
      "Epoch: 400, mean_losses: 0.0000, 0.0000, total_reward: 20.0, in 4.6796 secs\n",
      "Epoch: 500, mean_losses: 0.0000, 0.0000, total_reward: 15.0, in 6.8841 secs\n",
      "Epoch: 600, mean_losses: 0.0000, 0.0000, total_reward: 13.0, in 6.7288 secs\n",
      "Epoch: 700, mean_losses: 0.0000, 0.0000, total_reward: 57.0, in 6.5239 secs\n",
      "Epoch: 800, mean_losses: 0.0000, 0.0000, total_reward: 57.0, in 6.4343 secs\n",
      "Epoch: 900, mean_losses: 0.0000, 0.0000, total_reward: 14.0, in 6.2603 secs\n",
      "Epoch: 1000, mean_losses: 0.0000, 0.0000, total_reward: 16.0, in 6.6274 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 526 with reward 28.37\n",
      "\n",
      "# Training: Model 142\n",
      "Goal: Get average reward of 200.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_losses: 0.0010, 0.0000, total_reward: 9.0, in 4.1289 secs\n",
      "Epoch: 200, mean_losses: 0.0006, 0.0000, total_reward: 9.0, in 2.4726 secs\n",
      "Epoch: 300, mean_losses: 0.0004, 0.0000, total_reward: 11.0, in 2.9831 secs\n",
      "Epoch: 400, mean_losses: 0.0003, 0.0000, total_reward: 13.0, in 2.4032 secs\n",
      "Epoch: 500, mean_losses: 0.0003, 0.0000, total_reward: 15.0, in 2.6182 secs\n",
      "Epoch: 600, mean_losses: 0.0002, 0.0000, total_reward: 10.0, in 2.4510 secs\n",
      "Epoch: 700, mean_losses: 0.0002, 0.0000, total_reward: 11.0, in 2.5130 secs\n",
      "Epoch: 800, mean_losses: 0.0002, 0.0000, total_reward: 9.0, in 2.7339 secs\n",
      "Epoch: 900, mean_losses: 0.0002, 0.0000, total_reward: 9.0, in 2.4979 secs\n",
      "Epoch: 1000, mean_losses: 0.0002, 0.0000, total_reward: 9.0, in 2.7275 secs\n",
      "############# Goal Summary ############           \n",
      "Number of achieved goals: 0\n",
      "Max mean reward over 100 trials achieved at epoch 100 with reward 16.64\n"
     ]
    }
   ],
   "source": [
    "old_log = log_file\n",
    "from bayes_opt.util import load_logs\n",
    "\n",
    "load_logs(optimizer, logs=[old_log])\n",
    "optimizer.maximize(\n",
    "    init_points=1,\n",
    "    n_iter=40,\n",
    "    acq=\"ei\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
