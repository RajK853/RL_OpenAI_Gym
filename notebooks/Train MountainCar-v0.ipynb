{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MountainCar-v0\n",
    "Run the MountainCar-v0 simulation to train or test a model using Q-learning (DQN and DDQN).  \n",
    "Alternative method to train the model:  \n",
    "1. Open the command terminal in the root directory\n",
    "2. Execute the command ``python -m run.MountainCar_v0``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import gym\n",
    "import numpy as np\n",
    "import configparser\n",
    "from datetime import datetime\n",
    "import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf_v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "## Import local modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ROOT_DIR = os.path.abspath(os.path.join(os.path.abspath(\"\"), '..'))\n",
    "sys.path.insert(0, ROOT_DIR)\n",
    "from run import MountainCar_v0\n",
    "from src import ReplayBuffer\n",
    "from src.Utils import get_logger, eval_dict_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_DIR = \"log\"\n",
    "SUMM_DIR = \"summaries\"\n",
    "CONFIG_DIR = \"config\"\n",
    "ENV_NAME = \"MountainCar-v0\"\n",
    "SEEDS = np.random.randint(100, 1000, size=1, dtype=np.uint16)\n",
    "TF_CONFIG = tf_v1.ConfigProto(gpu_options=tf_v1.GPUOptions(per_process_gpu_memory_fraction=0.5), \n",
    "                              allow_soft_placement=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_result = False                        # Plots the result in matplotlib\n",
    "test_model_chkpt = None                    # Address to a trained model checkpoint; Train new model is none provided\n",
    "record_interval = 0\n",
    "epochs = 1000\n",
    "date_time = datetime.now().strftime(\"%d.%m.%Y %H.%M\")\n",
    "# Root directory needed to be specified explicitly in Jupyter Notebook\n",
    "summ_dir = os.path.join(ROOT_DIR, SUMM_DIR, \"{} {}\".format(ENV_NAME, date_time))\n",
    "log_file = os.path.join(summ_dir, LOG_DIR, \"Results {} {}.log\".format(ENV_NAME, date_time))\n",
    "config_file = os.path.join(ROOT_DIR, CONFIG_DIR, \"MountainCar-v0.ini\")\n",
    "os.makedirs(os.path.dirname(log_file), exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup logger directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(os.path.dirname(log_file), exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and unpack configurations\n",
    "Parameters are stored in **.ini file** under the **\\config** subdirectory.  \n",
    "Load the parameters from a given **config_file** and edit the configuration file to change the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dict = MountainCar_v0.get_configuration(config_file)\n",
    "init_kwargs, train_kwargs = config_dict[\"kwargs\"]\n",
    "log_init_kwargs, log_train_kwargs = config_dict[\"log_kwargs\"]\n",
    "mem_size = config_dict[\"others\"][\"mem_size\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run MountainCar-v0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0918 20:16:14.022605  1416 deprecation.py:506] From c:\\users\\raj k\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0918 20:16:14.216976  1416 deprecation.py:323] From c:\\users\\raj k\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\losses\\losses_impl.py:121: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Training: Model 1\n",
      "Goal: Get average reward of -110.00 over 100 consecutive trials!\n",
      "Epoch: 100, mean_loss: 2.4482, total_reward: -100.0, max_pos: 0.5096, in 91.4544 secs\n",
      "Epoch: 200, mean_loss: 1.1158, total_reward: -148.0, max_pos: 0.5216, in 73.5901 secs\n",
      "Epoch: 300, mean_loss: 0.9872, total_reward: -100.0, max_pos: 0.5048, in 72.7747 secs\n",
      "Epoch: 400, mean_loss: 0.4037, total_reward: -103.0, max_pos: 0.5065, in 61.6563 secs\n",
      "Epoch: 500, mean_loss: 0.1968, total_reward: -110.0, max_pos: 0.5166, in 64.1082 secs\n",
      "Epoch: 600, mean_loss: 0.1401, total_reward: -105.0, max_pos: 0.5163, in 58.3907 secs\n",
      "Epoch: 700, mean_loss: 0.1420, total_reward: -107.0, max_pos: 0.5034, in 64.1629 secs\n",
      "Epoch: 800, mean_loss: 0.0770, total_reward: -98.0, max_pos: 0.5137, in 60.5819 secs\n",
      "Epoch: 900, mean_loss: 0.1125, total_reward: -104.0, max_pos: 0.5116, in 59.4749 secs\n",
      "Epoch: 1000, mean_loss: 0.1770, total_reward: -138.0, max_pos: 0.5119, in 67.1129 secs\n",
      "                                                  \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Goals achieved: 77                  \n",
      "First goal achieved: -109.94 mean reward at 539 epoch.\n",
      "Max goal achieved: -107.63 mean reward at 601 epoch.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create environment, replay buffer and logger\n",
    "env = gym.make(ENV_NAME)\n",
    "mem = ReplayBuffer(mem_size)\n",
    "logger = get_logger(log_file)\n",
    "# Run the program\n",
    "for model_i, seed in enumerate(SEEDS, start=1):\n",
    "    MountainCar_v0.run(env, seed, mem, logger, summ_dir, epochs, init_kwargs, train_kwargs, \n",
    "                       log_init_kwargs, log_train_kwargs, plot_result, model_i=model_i, \n",
    "                       sess_config=TF_CONFIG, test_model_chkpt=test_model_chkpt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
